{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np \n",
    "import collections\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pylab as py\n",
    "import os\n",
    "import csv\n",
    "from collections import Counter\n",
    "import re\n",
    "import subprocess\n",
    "from Bio.Application import _Option, AbstractCommandline, _Switch \n",
    "import gzip\n",
    "import pprint\n",
    "\n",
    "\n",
    "## Plotting parameters ##\n",
    "\n",
    "plt.rcParams[\"xtick.labelsize\"] = 'medium'\n",
    "plt.rcParams[\"ytick.labelsize\"] = 'medium'\n",
    "plt.rcParams['figure.figsize'] = (14.0, 12.0)\n",
    "\n",
    "\n",
    "## Define Classes and Functions\n",
    "\n",
    "class UstacksCommandLine(AbstractCommandline):\n",
    "    def __init__(self, cmd=\"ustacks\", **kwargs):\n",
    "        \"\"\"\n",
    "        # Any ustacks option and switch\n",
    "        >>> cline_args = {'t': 'fastq',\n",
    "        ...               'f': '../../dan_data/OBY01_1.fil.fq_1',\n",
    "        ...               'o': '../../dan_data/OBY01_1.fi/M_tests/M_1',\n",
    "        ...               'i': 1,\n",
    "        ...               'm': 6,\n",
    "        ...               'M': 1,\n",
    "        ...               'p': 3,\n",
    "        ...               'r': True,\n",
    "        ...               'd': True}\n",
    "        \n",
    "        # This creates a command line object\n",
    "        >>> ustacks_cline = UstacksCommandLine(**cline_args)\n",
    "        \n",
    "        # This prints a string representation\n",
    "        >>> print ustacks_cline\n",
    "        ustacks -t fastq -f ../../dan_data/OBY01_1.fil.fq_1 -o ../../dan_data/OBY01_1.fi/M_tests/M_1 -i 1 -m 6 -M 1 -p 3 -r -d\n",
    "        \n",
    "        # This runs ustacks\n",
    "        >>> stdout, stderr = ustacks_cline()\n",
    "        \n",
    "        # This prints the first line in the allele files of the example reuslts\n",
    "        >>> with open('../../dan_data/OBY01_1.fi/M_tests/M_1/OBY01_1.fil.alleles.tsv') as alleles:\n",
    "        ...     print alleles.readlines()[1].rstrip().split()\n",
    "        ['0', '1', '1', 'C', '78.04', '167']\n",
    "        \"\"\"\n",
    "        \n",
    "        self.parameters = [\n",
    "            _Option([\"-t\", \"t\"],\n",
    "                    \"input file Type. Supported types: fasta, fastq, gzfasta, or gzfastq\",\n",
    "                    is_required=True,\n",
    "                    checker_function=lambda value : value in [\"fasta\", \n",
    "                                                              \"fastq\",\n",
    "                                                              \"gzfasta\",\n",
    "                                                              \"gzfastq\"],\n",
    "                    equate=False),\n",
    "            _Option([\"-f\", \"f\"],\n",
    "                    \"input file path\",\n",
    "                    is_required=True,\n",
    "                    filename=True,\n",
    "                    equate=False),\n",
    "            _Option([\"-o\", \"o\"],\n",
    "                    \"output path to write results\",\n",
    "                    is_required=False,\n",
    "                    filename=True,\n",
    "                    equate=False),\n",
    "            _Option([\"-i\", \"i\"],\n",
    "                    \"SQL ID to insert into the output to identify this sample\",\n",
    "                    is_required=False,\n",
    "                    equate=False),\n",
    "            _Option([\"-m\", \"m\"],\n",
    "                    \"Minimum depth of coverage required to create a stack (default 3)\",\n",
    "                    is_required=False,\n",
    "                    checker_function=lambda value : isinstance(value,int),\n",
    "                    equate=False),\n",
    "            _Option([\"-M\", \"M\"],\n",
    "                    \"Maximum distance (in nucleotides) allowed between stacks (default 2)\",\n",
    "                    is_required=False,\n",
    "                    checker_function=lambda value : isinstance(value,int),\n",
    "                    equate=False),\n",
    "            _Option([\"-N\", \"N\"],\n",
    "                    \"Maximum distance allowed to align secondary reads to primary stacks (default: M + 2)\",\n",
    "                    is_required=False,\n",
    "                    checker_function=lambda value : isinstance(value,int),\n",
    "                    equate=False),\n",
    "            _Switch([\"-R\", \"R\"],\n",
    "                    \"retain unused reads\"), \n",
    "            _Switch([\"-H\", \"H\"],\n",
    "                    \"disable calling haplotypes from secondary reads\"),\n",
    "            _Option([\"-p\", \"p\"],\n",
    "                    \"enable parallel execution with num_threads threads\",\n",
    "                    is_required=False,\n",
    "                    checker_function=lambda value : isinstance(value,int),\n",
    "                    equate=False),  \n",
    "            _Switch([\"-h\", \"h\"],\n",
    "                    \"display this help messsage\"),\n",
    "            \n",
    "            # Stack assembly options:\n",
    "            _Switch([\"-r\", \"r\"],\n",
    "                    \"enable the Removal algorithm, to drop highly-repetitive stacks (and nearby errors) from the algorithm\"), \n",
    "            _Switch([\"-d\", \"d\"],\n",
    "                    \"enable the Deleveraging algorithm, used for resolving over merged tags\"),\n",
    "            _Option([\"--max_locus_stacks\", \"-max_locus_stacks\",\"max_locus_stacks\"],\n",
    "                    \"maximum number of stacks at a single de novo locus (default 3)\",\n",
    "                    is_required=False,\n",
    "                    checker_function=lambda value : isinstance(value,int),\n",
    "                    equate=False),\n",
    "            \n",
    "            # Model options:\n",
    "            _Option([\"--model_type\", \"-model_type\",\"model_type\"],\n",
    "                    \"either 'snp' (default), 'bounded', or 'fixed'\",\n",
    "                    is_required=False,\n",
    "                    checker_function=lambda value : value in [\"snp\", \n",
    "                                                              \"bounded\",\n",
    "                                                              \"fixed\"],\n",
    "                    equate=False),\n",
    "            \n",
    "            # For the SNP or Bounded SNP model: \n",
    "            _Option([\"--alpha\", \"-alpha\",\"alpha\"],\n",
    "                    \"chi square significance level required to call a heterozygote or homozygote, either 0.1, 0.05 (default), 0.01, or 0.001\",\n",
    "                    is_required=False,\n",
    "                    checker_function=lambda value : value in [0.1, \n",
    "                                                              0.05,\n",
    "                                                              0.01,\n",
    "                                                              0.001],\n",
    "                    equate=False),\n",
    "            \n",
    "            \n",
    "            # For the Bounded SNP model:\n",
    "            _Option([\"--bound_low\", \"-bound_low\",\"bound_low\"],\n",
    "                    \"lower bound for epsilon, the error rate, between 0 and 1.0 (default 0)\",\n",
    "                    is_required=False,\n",
    "                    checker_function=lambda value : 0 <= value <= 1,\n",
    "                    equate=False),\n",
    "            _Option([\"--bound_high\", \"-bound_high\",\"bound_high\"],\n",
    "                    \"upper bound for epsilon, the error rate, between 0 and 1.0 (default 1)\",\n",
    "                    is_required=False,\n",
    "                    checker_function=lambda value : 0 <= value <= 1,\n",
    "                    equate=False),\n",
    "            \n",
    "            # For the Fixed model:\n",
    "            _Option([\"--bc_err_freq\", \"-bc_err_freq\",\"bc_err_freq\"],\n",
    "                    \"specify the barcode error frequency, between 0 and 1.0\",\n",
    "                    is_required=False,\n",
    "                    checker_function=lambda value : 0 <= value <= 1,\n",
    "                    equate=False)\n",
    "                           ]\n",
    "        AbstractCommandline.__init__(self, cmd, **kwargs) \n",
    "\n",
    "## With this uncommented, the examples in the \n",
    "## docstring will be run and the outputs compared\n",
    "#if __name__ == \"__main__\":\n",
    "#    import doctest\n",
    "#    doctest.testmod()\n",
    "\n",
    "\n",
    "## this function takes the string to be searched and a dictionary of replacements ------------------------------------------------------------\n",
    "\n",
    "def replace_all(text,dic): \n",
    "    for i, j in dic.iteritems(): \n",
    "        text = text.replace(i,j) ## for each dictionary entry, replace the \"key\" with the \"value\" in the text\n",
    "    return text\n",
    "\n",
    "\n",
    "## A cool little helper function for \"natural sorting\". (no idea how it works though!) -------------------------------------------------------\n",
    "def natural_key(string_): \n",
    "    return [int(s) if s.isdigit() else s for s in re.split(r'(\\d+)', string_)]\n",
    "\n",
    "\n",
    "## Function to count the length of a file ----------------------------------------------------------------------------------------------------\n",
    "    \n",
    "def file_len(data):\n",
    "    for i, l in enumerate(data):\n",
    "        pass\n",
    "    return i + 1\n",
    "    \n",
    "## Function for generating random colour maps for the samples\n",
    "\n",
    "def random_colour_generator(nlabels, type='bright', first_color_black=True, last_color_black=False, verbose=True):\n",
    "    \"\"\"\n",
    "    Creates a random colormap to be used together with matplotlib. Useful for segmentation tasks\n",
    "    :param nlabels: Number of labels (size of colormap)\n",
    "    :param type: 'bright' for strong colors, 'soft' for pastel colors\n",
    "    :param first_color_black: Option to use first color as black, True or False\n",
    "    :param last_color_black: Option to use last color as black, True or False\n",
    "    :param verbose: Prints the number of labels and shows the colormap. True or False\n",
    "    :return: colormap for matplotlib\n",
    "    \"\"\"\n",
    "    from matplotlib.colors import LinearSegmentedColormap\n",
    "    import colorsys\n",
    "    import numpy as np\n",
    "\n",
    "\n",
    "    if type not in ('bright', 'soft'):\n",
    "        print ('Please choose \"bright\" or \"soft\" for type')\n",
    "        return\n",
    "\n",
    "    if verbose:\n",
    "        print('Number of labels: ' + str(nlabels))\n",
    "\n",
    "    # Generate color map for bright colors, based on hsv\n",
    "    if type == 'bright':\n",
    "        randHSVcolors = [(np.random.uniform(low=0.0, high=1),\n",
    "                          np.random.uniform(low=0.2, high=1),\n",
    "                          np.random.uniform(low=0.9, high=1)) for i in xrange(nlabels)]\n",
    "\n",
    "        # Convert HSV list to RGB\n",
    "        randRGBcolors = []\n",
    "        for HSVcolor in randHSVcolors:\n",
    "            randRGBcolors.append(colorsys.hsv_to_rgb(HSVcolor[0], HSVcolor[1], HSVcolor[2]))\n",
    "\n",
    "        if first_color_black:\n",
    "            randRGBcolors[0] = [0, 0, 0]\n",
    "\n",
    "        if last_color_black:\n",
    "            randRGBcolors[-1] = [0, 0, 0]\n",
    "\n",
    "        random_colormap = LinearSegmentedColormap.from_list('new_map', randRGBcolors, N=nlabels)\n",
    "\n",
    "    # Generate soft pastel colors, by limiting the RGB spectrum\n",
    "    if type == 'soft':\n",
    "        low = 0.6\n",
    "        high = 0.95\n",
    "        randRGBcolors = [(np.random.uniform(low=low, high=high),\n",
    "                          np.random.uniform(low=low, high=high),\n",
    "                          np.random.uniform(low=low, high=high)) for i in xrange(nlabels)]\n",
    "\n",
    "        if first_color_black:\n",
    "            randRGBcolors[0] = [0, 0, 0]\n",
    "\n",
    "        if last_color_black:\n",
    "            randRGBcolors[-1] = [0, 0, 0]\n",
    "        random_colormap = LinearSegmentedColormap.from_list('new_map', randRGBcolors, N=nlabels)\n",
    "\n",
    "    # Display colorbar\n",
    "    if verbose:\n",
    "        from matplotlib import colors, colorbar\n",
    "        from matplotlib import pyplot as plt\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(15, 0.5))\n",
    "\n",
    "        bounds = np.linspace(0, nlabels, nlabels + 1)\n",
    "        norm = colors.BoundaryNorm(bounds, nlabels)\n",
    "\n",
    "        cb = colorbar.ColorbarBase(ax, cmap=random_colormap, norm=norm, spacing='proportional', ticks=None,\n",
    "                                   boundaries=bounds, format='%1i', orientation=u'horizontal')\n",
    "\n",
    "    return random_colormap\n",
    "\n",
    "\n",
    "## Function to make and run the command line. -----------------------------------------------------------------------------\n",
    "def make_and_run_command_line(param, value, parent_dir_path, sample, file_format, threads, ID, run_switch):\n",
    "    \n",
    "    \"\"\"\n",
    "    Makes and runs the command line using the UstacksCommandLine class\n",
    "    \"\"\"\n",
    "    \n",
    "    # fixed values\n",
    "    default = {'M': 2, \n",
    "               'm': 3}\n",
    "              # MS as stacks default (doesn't need to be specified in command line)\n",
    "    \n",
    "    batch_params = {}\n",
    "    \n",
    "    sample_name = sample.split(\".\")[0]\n",
    "    \n",
    "    dirname = '%s%s/%s_tests/%s_%i'%(parent_dir_path,sample_name,param,param,value) ## make output directory\n",
    "            \n",
    "    # make command line\n",
    "    args = {}\n",
    "    args['t'] = file_format\n",
    "    args['p'] = threads\n",
    "    args['d'] = True\n",
    "    args['r'] = True\n",
    "    args['i'] = str(ID)\n",
    "    args['f'] = \"%s%s\"%(parent_dir_path,str(sample))\n",
    "    args['o'] = dirname\n",
    "        \n",
    "    if param == 'MS':\n",
    "        args['max_locus_stacks'] = value\n",
    "        args.update(default)\n",
    "    else:\n",
    "        args[param] = value\n",
    "        for key in default:\n",
    "            if not key == param:\n",
    "                args[key] = default[key]\n",
    "                    \n",
    "    cline = UstacksCommandLine(**args)\n",
    "        \n",
    "    if run_switch == 1:\n",
    "        stderr, stdout = cline()        \n",
    "        \n",
    "    batch_params[\"%s_%i\"%(args['i'], value)] = args ## can return this if needed, but all params are in the command line.         \n",
    "        \n",
    "    return cline\n",
    "\n",
    "\n",
    "\n",
    "### This function gets information on the blacklisted or deleveraged loci in stacks - useful for looking at problems associated with repeats.\n",
    "\n",
    "def blacklister(file_name, verbose):\n",
    "    \n",
    "    Blacklisted_lumberjacks = 0\n",
    "    Blacklisted_multistack = 0\n",
    "    Deleveraged_Lumberjacks = 0\n",
    "    Deleveraged_mulitstacks = 0\n",
    "    Deleved_blacklisted_multistacks = 0\n",
    "    \n",
    "    Blacklisted_lumberjacks_list = []\n",
    "    Blacklisted_multistack_list = []\n",
    "    Deleveraged_lumberjacks_list = []\n",
    "    Deleveraged_mulitstacks_list = []\n",
    "    Deleved_blacklisted_multistacks_list = []\n",
    "\n",
    "    if file_name.endswith(\".gz\"):\n",
    "        csvfile = gzip.open(file_name, 'rb')\n",
    "    else:\n",
    "        csvfile = open(file_name, 'rb')\n",
    "    csvread = csv.reader(csvfile, delimiter =\"\\t\") ## read csv in \n",
    "    \n",
    "    for line in csvread:\n",
    "        if \"consensus\" in line:\n",
    "            tag_ID = line[2]\n",
    "            ## if tag had very high coverage and could not be deleveraged\n",
    "            if line[10] == \"0\" and line[11] == \"1\" and line[12] == \"1\":\n",
    "                Blacklisted_lumberjacks += 1\n",
    "                Blacklisted_lumberjacks_list.append(tag_ID)\n",
    "            ## if tag was a multistack but could not be deleveraged\n",
    "            elif line[10] == \"0\" and line[11] == \"1\" and line[12] == \"0\":\n",
    "                Blacklisted_multistack += 1\n",
    "                Blacklisted_multistack_list.append(tag_ID)\n",
    "            ## if tag was a lumberjack and could be deleveraged\n",
    "            elif line[10] == \"1\" and line[11] == \"0\" and line[12] == \"1\":\n",
    "                Deleveraged_Lumberjacks += 1\n",
    "                Deleveraged_lumberjacks_list.append(tag_ID)\n",
    "            ## if tag was a multistack and could be deleveraged\n",
    "            elif line[10] == \"1\" and line[11] == \"0\" and line[12] == \"0\":\n",
    "                Deleveraged_mulitstacks += 1\n",
    "                Deleveraged_mulitstacks_list.append(tag_ID)\n",
    "            ## if tag was a multistack, passed the deleveraging but was blacklisted for another reason. . . ?\n",
    "            elif line[10] == \"1\" and line[11] == \"1\" and line[12] == \"0\":\n",
    "                Deleved_blacklisted_multistacks += 1\n",
    "                Deleved_blacklisted_multistacks_list.append(tag_ID)\n",
    "\n",
    "    if verbose == True:\n",
    "        print \"\\tNumber of un-deleveraged lumberjacks blacklisted = %s\" % (Blacklisted_lumberjacks)\n",
    "        print \"\\tNumber of un-deleveraged multistack loci blacklisted = %s\" % (Blacklisted_multistack)\n",
    "        print \"\\tNumber of deleveraged lumberjacks = %s\" % (Deleveraged_Lumberjacks)\n",
    "        print \"\\tNumber of deleveraged multistack loci = %s\" % (Deleveraged_mulitstacks)\n",
    "        print \"\\tNumber of deleveraged but still blacklisted multistack loci = %s\" % (Deleved_blacklisted_multistacks)\n",
    "    \n",
    "    return Blacklisted_lumberjacks_list, Blacklisted_multistack_list, Deleveraged_lumberjacks_list, Deleveraged_mulitstacks_list, Deleved_blacklisted_multistacks_list \n",
    "    \n",
    "    \n",
    "\n",
    "## This function counts the number of tags in a file ------------------------------------------------------------------------------\n",
    "\n",
    "def Tag_counter(tags_file, parameter, value, verb):   \n",
    "    \n",
    "    \"\"\"\n",
    "    Counts the number of tags found by the ustacks module of Stacks in a given tag.tsv file.\n",
    "    It works by simply counting the number of lines with the work \"consensus\" in them in the tags file. \n",
    "    \n",
    "    Arguments:\n",
    "        sample_directory - the parent test directory containing the intitial fastq files.\n",
    "        parameter - the parameter being addressed. \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    ## get file names and paths\n",
    "    tag_data = {}\n",
    "    param_output_path = tags_file.rpartition(\"/\")[0]\n",
    "                                \n",
    "    if tags_file.endswith(\".gz\"):\n",
    "        data_file = gzip.open(tags_file, 'r')\n",
    "    else: \n",
    "        data_file = open(tags_file, 'r') ## looking in tags files for all the tests for this parameter\n",
    "    \n",
    "    total_tags = 0\n",
    "    tag_tally = 0\n",
    "    N_blacklisted = 0\n",
    "                \n",
    "    for line in data_file.readlines()[1:]:\n",
    "        if 'consensus' in line:\n",
    "            total_tags += 1\n",
    "            tag_id = str(line.split()[2])\n",
    "            blacklist_flag = str(line.split()[8])\n",
    "                        \n",
    "            ## check that loci weren't blacklisted\n",
    "            if blacklist_flag == \"1\":\n",
    "                N_blacklisted += 1\n",
    "            else:\n",
    "                tag_tally +=1\n",
    "    \n",
    "    if verb == True:\n",
    "        print \"%s at %s = %s Total_tags = %s, Good tags = %s, N blacklisted = %s\" % (tags_file.rpartition(\"/\")[2], parameter, value, total_tags, tag_tally, N_blacklisted)\n",
    "    \n",
    "    return tag_tally\n",
    "\n",
    "\n",
    "\n",
    "def Tag_plotter(Outputs_dict):\n",
    "    \n",
    "    \n",
    "    colmap = random_colour_generator(100, verbose=False)\n",
    "    \n",
    "    ## Count number of plots needed\n",
    "\n",
    "    params_needed = []\n",
    "    plots_needed = []\n",
    "    samples_needed = []\n",
    "\n",
    "    for sample in Outputs_dict: ## sample level\n",
    "        if sample.endswith(\"fq\") or sample.endswith(\"gz\"):\n",
    "            for param in Outputs_dict[sample]: ## each param within sample\n",
    "                for value in Outputs_dict[sample][param]:\n",
    "                    if \"N_tags\" in Outputs_dict[sample][param][value].keys():\n",
    "                        plots_needed.append((sample, param))\n",
    "                        params_needed.append(param)\n",
    "\n",
    "    params_needed = set(params_needed)\n",
    "    plots_needed = set(plots_needed)\n",
    "    Total_subplots_needed = len(plots_needed) + len(params_needed)\n",
    "\n",
    "    \n",
    "    n_rows = (np.round(Total_subplots_needed/3)+1)\n",
    "    n_cols = 3\n",
    "\n",
    "    sample_plot_index = 1\n",
    "    sample_colour_index = 1\n",
    "    param_tracker = []\n",
    "    \n",
    "    fig = plt.figure(figsize= (20,Total_subplots_needed*2))\n",
    "    #fig.subplots_adjust(hspace = 0.5, wspace = 0.25) ## adjust subplots\n",
    "\n",
    "    sample_counter = 0\n",
    "    param_value_counter = 0\n",
    "\n",
    "\n",
    "\n",
    "    for sample in Outputs_dict: ## sample level\n",
    "        if sample.endswith(\"fq\") or sample.endswith(\"gz\"):\n",
    "            sample_name = sample.split(\".\")[0]\n",
    "            for param in Outputs_dict[sample]:\n",
    "                if (sample, param) in plots_needed:\n",
    "\n",
    "                    ## get the index right for the comparison plots\n",
    "\n",
    "                    if param == \"M\":\n",
    "                        comparison_plot_index = Total_subplots_needed\n",
    "\n",
    "                    elif param == \"m\" and not \"M\" in params_needed:\n",
    "                        comparison_plot_index = Total_subplots_needed\n",
    "\n",
    "                    elif param == \"m\" and \"M\" in params_needed:\n",
    "                        comparison_plot_index = Total_subplots_needed -1\n",
    "\n",
    "                    elif param == \"MS\" and \"M\" not in params_needed and \"m\" not in params_needed:\n",
    "                        comparison_plot_index = Total_subplots_needed\n",
    "\n",
    "                    elif param == \"MS\" and \"M\" in params_needed and \"m\" not in params_needed:\n",
    "                        comparison_plot_index = Total_subplots_needed -1\n",
    "\n",
    "                    elif param == \"MS\" and \"M\" not in params_needed and \"m\" in params_needed:\n",
    "                        comparison_plot_index = Total_subplots_needed -1\n",
    "\n",
    "                    elif param == \"MS\" and \"M\" in params_needed and \"m\" in params_needed:\n",
    "                        comparison_plot_index = Total_subplots_needed -2\n",
    "\n",
    "\n",
    "                    ## Make the data\n",
    "\n",
    "                    x = []\n",
    "                    y = []\n",
    "                    value_range = []\n",
    "\n",
    "                    for value in Outputs_dict[sample][param]: ## each value for each param in each sample\n",
    "\n",
    "                        value_range.append(int(value))\n",
    "\n",
    "                        if \"N_tags\" in Outputs_dict[sample][param][value]:\n",
    "\n",
    "                            x.append(value)\n",
    "                            y.append(Outputs_dict[sample][param][value][\"N_tags\"])\n",
    "\n",
    "                    ## If there is data present, plot it\n",
    "\n",
    "                    if len(y) > 0:\n",
    "\n",
    "                        ## individual plots\n",
    "                        ax1 = plt.subplot(n_rows,n_cols,sample_plot_index)\n",
    "                        ax1.set_xlim(min(value_range)-1, max(value_range)+1)\n",
    "                        ax1.set_xticks(range(min(value_range)-1, max(value_range)+2, 1))\n",
    "                        ax1.plot(x,y, color = (colmap(sample_colour_index)),linewidth = 1.5,markersize = 3, marker = \"o\")\n",
    "                        ax1.set_title(sample)\n",
    "                        ax1.set_xlabel(\"%s Value\" % (param), fontsize = 10)\n",
    "                        ax1.set_ylabel(\"Number of tags\", fontsize = 10)\n",
    "\n",
    "\n",
    "                        ## Combined plot\n",
    "                        ax2 =plt.subplot(n_rows,n_cols,comparison_plot_index)\n",
    "                        ax2.set_xlim(min(value_range)-1, max(value_range)+1)\n",
    "                        ax2.set_xticks(range(min(value_range)-1, max(value_range)+2, 1))\n",
    "                        ax2.plot(x,y, color =(colmap(sample_colour_index)), label = sample_name, linewidth = 1.5,  marker = \"o\")\n",
    "                        ax2.set_title(\"All\")\n",
    "                        ax2.set_xlabel(\"%s Value\" % (param), fontsize = 10)\n",
    "                        ax2.set_ylabel(\"Number of tags\", fontsize = 10)\n",
    "                        \n",
    "                        ax2.legend(loc = 2, fontsize = 8)\n",
    "\n",
    "                        sample_plot_index +=1\n",
    "                    else:\n",
    "                        pass\n",
    "\n",
    "            sample_colour_index += 1\n",
    "\n",
    "    plt.tight_layout()\n",
    "    fig.savefig(\"%s/%s\" % (Outputs_dict[\"parent_directory\"], \"Tag_counts.pdf\"), format = \"pdf\")\n",
    "    fig.show()\n",
    "    \n",
    "    \n",
    " \n",
    " ## This function counts the coverage at each non-blacklisted locus in a ustacks tags.tsv output file. ----------------------------------------------------------\n",
    "    \n",
    "def coverage_counter(file_name, verb): ## Need to add help info to this and annotate properly!!\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    This function calculates the coverage of each tag in the ustacks tags.tsv output\n",
    "    as long as that locus has not been blacklisted. It outputs a text file containing all \n",
    "    tag IDs and coverage values, as well as a histogram of the tag coverage into the same \n",
    "    directory as the input file.\n",
    "    \n",
    "    - filename: the full path to the tags.tsv file\n",
    "    \n",
    "    This function works in conjuction with coverage_counter_looper and returns a dictionary for this.\n",
    "    \n",
    "    \"\"\"    \n",
    "    \n",
    "    csvcol3 = []        \n",
    "    \n",
    "    if file_name.endswith(\".gz\"):\n",
    "        csvfile = gzip.open(file_name, 'rb')\n",
    "    else: \n",
    "        csvfile = open(file_name, 'rb') \n",
    "    \n",
    "    csvread = csv.reader(csvfile, delimiter =\"\\t\") ## read csv in    \n",
    "    blacklisted_loci = []\n",
    "    \n",
    "    sample_name = file_name.rpartition(\"/\")[2].split(\".\")[0]\n",
    "    tags_file_parameter = file_name.rpartition(\"/\")[0].rpartition(\"/\")[2].split(\"_\")[0]\n",
    "    tags_file_val = file_name.rpartition(\"/\")[0].rpartition(\"/\")[2].split(\"_\")[1]\n",
    "    \n",
    "    \n",
    "    n_blacklisted = 0\n",
    "    n_counted = 0\n",
    "    \n",
    "    for line in csvread:\n",
    "        if not line[0].startswith('#'): # outputs in new version of stacks start with a comment \n",
    "            tag_ID = line[2]\n",
    "            if \"consensus\" in line and line[11] == \"1\": ## Check that the locus is not blacklisted!\n",
    "                n_blacklisted += 1\n",
    "                blacklisted_loci.append(tag_ID)\n",
    "            if \"model\" not in line and \"consensus\" not in line:\n",
    "                n_counted += 1\n",
    "                csvcol3.append(tag_ID) ## for each read, add its tag ID to a list.\n",
    "    \n",
    "    coverage_count = collections.Counter(csvcol3) ## count the occurance of each tag ID in the list to get read depths per locus\n",
    "    good_counts = {}\n",
    "    \n",
    "    ## Now remove coverage counts for loci in the blacklist. \n",
    "    \n",
    "    for locus in coverage_count: \n",
    "        if locus not in blacklisted_loci:\n",
    "            good_counts[locus] = coverage_count[locus]\n",
    "    \n",
    "    \n",
    "    ## OUTPUTS -------------------------\n",
    "    \n",
    "    outdir = file_name.rpartition(\"/\")[0] ## same directory as the input file\n",
    "    f = open(\"%s/Coverage data.txt\" % outdir, 'w') ## txt file for coverage data    \n",
    "        \n",
    "    for i,j in good_counts.iteritems():\n",
    "        f.write(\"%s\\t%s\\n\" % (str(i), str(j) )) ## write the coverage data to the txt file\n",
    "    \n",
    "    ## Can make individual histograms for each sample if you want. Just un comment this section ------\n",
    "    \n",
    "    x = good_counts.values()\n",
    "    #fig = plt.figure()\n",
    "    #ax = fig.add_subplot(111)\n",
    "    #ax.hist(x, bins=max(x), range = (1, np.mean(x)+(2*np.std(x))))\n",
    "    #ax.set_title(\"%s, %s = %s\" % (sample_name, tags_file_parameter, tags_file_val), fontsize = 15) ####\n",
    "    #ax.set_xlabel(\"Coverage\", fontsize = 12)\n",
    "    #ax.set_ylabel(\"Frequency\", fontsize = 12)\n",
    "    #ax.text(0.6, 0.95, \"Mean tag coverage = %s (+/- %s)\" % (np.round(np.mean(x),2),np.round(np.std(x),2)) , transform=ax.transAxes, fontsize = 13)\n",
    "    #plt.savefig(\"%s/Coverage.pdf\" % outdir)\n",
    "    \n",
    "    #plt.show()\n",
    "    #plt.close()\n",
    "    \n",
    "    f.close()\n",
    "    \n",
    "    if verb == True:\n",
    "        print \"Mean and SD of coverage for %s, %s=%s:  %s (+/- %s)\\n\" % (sample_name, tags_file_parameter ,tags_file_val , np.round(np.mean(x),2),np.round(np.std(x),2))\n",
    "    \n",
    "    return good_counts\n",
    "\n",
    "\n",
    "## Coverage plotter -----------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "def Coverage_plotter(Outputs):\n",
    "\n",
    "    colmap = random_colour_generator(100, verbose=False)\n",
    "    \n",
    "    ## Count number of plots needed\n",
    "    \n",
    "    params_needed = []\n",
    "    plots_needed = []\n",
    "    samples_needed = []\n",
    "\n",
    "    for sample in Outputs: ## sample level\n",
    "        if sample.endswith(\"fq\") or sample.endswith(\"gz\"):\n",
    "            for param in Outputs[sample]: ## each param within sample\n",
    "                for value in Outputs[sample][param]:\n",
    "                    if \"N_tags\" in Outputs[sample][param][value].keys():\n",
    "                        plots_needed.append((sample, param))\n",
    "                        params_needed.append(param)\n",
    "\n",
    "    params_needed = set(params_needed)\n",
    "    plots_needed = set(plots_needed)\n",
    "    Total_subplots_needed = len(plots_needed) + len(params_needed)\n",
    "    \n",
    "    n_rows = (np.round(Total_subplots_needed/3)+1)\n",
    "    n_cols = 3\n",
    "\n",
    "    sample_plot_index = 1\n",
    "    sample_colour_index = 1\n",
    "    param_tracker = []\n",
    "    \n",
    "    fig = plt.figure(figsize= (20,Total_subplots_needed*3))\n",
    "\n",
    "    for sample in Outputs: ## sample level\n",
    "        if sample.endswith(\"fq\") or sample.endswith(\"gz\"):\n",
    "            sample_name = sample.split(\".\")[0]    \n",
    "            for param in Outputs[sample]:\n",
    "                if (sample,param) in plots_needed:\n",
    "\n",
    "                    ## get the index right for the comparison plots\n",
    "\n",
    "                    if param == \"M\":\n",
    "                        comparison_plot_index = Total_subplots_needed\n",
    "\n",
    "                    elif param == \"m\" and not \"M\" in params_needed:\n",
    "                        comparison_plot_index = Total_subplots_needed\n",
    "\n",
    "                    elif param == \"m\" and \"M\" in params_needed:\n",
    "                        comparison_plot_index = Total_subplots_needed -1\n",
    "\n",
    "                    elif param == \"MS\" and \"M\" not in params_needed and \"m\" not in params_needed:\n",
    "                        comparison_plot_index = Total_subplots_needed\n",
    "\n",
    "                    elif param == \"MS\" and \"M\" in params_needed and \"m\" not in params_needed:\n",
    "                        comparison_plot_index = Total_subplots_needed -1\n",
    "\n",
    "                    elif param == \"MS\" and \"M\" not in params_needed and \"m\" in params_needed:\n",
    "                        comparison_plot_index = Total_subplots_needed -1\n",
    "\n",
    "                    elif param == \"MS\" and \"M\" in params_needed and \"m\" in params_needed:\n",
    "                        comparison_plot_index = Total_subplots_needed -2\n",
    "\n",
    "\n",
    "                    ## Make the data\n",
    "\n",
    "                    x = [] ## parameter values\n",
    "                    y = []\n",
    "                    mean_y = []\n",
    "                    std_y = []\n",
    "                    e = []\n",
    "\n",
    "                    upper_95 = 0\n",
    "                    x_labs = []\n",
    "\n",
    "                    for value in Outputs[sample][param]: ## each value for each param in each sample\n",
    "                        if \"Coverage\" in Outputs[sample][param][value]:\n",
    "\n",
    "                            x.append(value)\n",
    "                            y.append(Outputs[sample][param][value][\"Coverage\"].values())\n",
    "                            mean_y.append(np.mean(Outputs[sample][param][value][\"Coverage\"].values()))\n",
    "                            std_y.append(np.std(Outputs[sample][param][value][\"Coverage\"].values()))\n",
    "                            x_labs.append(int(value))\n",
    "                            if np.percentile(Outputs[sample][param][value][\"Coverage\"].values(), 95) > upper_95:\n",
    "                                upper_95 = np.percentile(Outputs[sample][param][value][\"Coverage\"].values(), 95)\n",
    "                        else:\n",
    "                            print \"Coverage data not in\", sample, param, value\n",
    "                    ## If there is data present, plot it\n",
    "\n",
    "                    if len(y) > 0:\n",
    "\n",
    "                        ax = plt.subplot(n_rows,n_cols,sample_plot_index)\n",
    "                        ax.set_ylim(0, upper_95)\n",
    "                        bp = ax.boxplot(y, labels= x_labs) # '%so-.' % (colours[sample_colour_and_plot_index]),linewidth = 1.5,markersize = 3, \n",
    "                        ax.set_title(\"%s\" % (sample_name))\n",
    "                        ax.set_xlabel(\"%s Value\" % (param), fontsize = 10)\n",
    "                        ax.set_ylabel(\"Tag coverage\", fontsize = 10)\n",
    "\n",
    "                        ## Combined plot\n",
    "                        ax1 = plt.subplot(n_rows,n_cols,comparison_plot_index)\n",
    "                        ax1.set_xlim(min(int(i) for i in x_labs)-1, max(int(i) for i in x_labs)+1)\n",
    "                        ax1.set_xticks(range(min([int(i) for i in x_labs])-1, max([int(i) for i in x_labs])+2, 1))\n",
    "                        ax1.plot(x, mean_y, label = sample_name, color =(colmap(sample_colour_index)), marker = \"o\")\n",
    "                        ax1.set_title(\"Comparison of mean tag coverage\")\n",
    "                        ax1.set_xlabel(\"%s Value\" % (param), fontsize = 10)\n",
    "                        ax1.set_ylabel(\"Mean tag coverage\", fontsize = 10)\n",
    "\n",
    "                        ax1.legend(loc = 2, fontsize = 8)\n",
    "\n",
    "                        sample_plot_index += 1\n",
    "                    else:\n",
    "                        pass\n",
    "\n",
    "            sample_colour_index += 1\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    #fig.suptitle(\"Change in Mean tag coverage with Incrementing parameter values\") \n",
    "    fig.savefig(\"%s/%s\" % (Outputs[\"parent_directory\"], \"Coverage.pdf\"), format = \"pdf\")\n",
    "    #fig.show()\n",
    "\n",
    "    \n",
    "\n",
    "def IncreMental_U(Setup_dict):\n",
    "    \n",
    "    \"\"\"\n",
    "    Incremental_U takes a directory of sample fastq or fastq.gz files, and runs Ustacks for\n",
    "    a specified set of values for the parameters -M, -m and --max_locus_stacks.    \n",
    "    \n",
    "    This function is designed to work with as many samples as needed, however it is recommended \n",
    "    that the number is kept below 20, as plots will become large and difficult to read.\n",
    "    \n",
    "    One important thing to note is that sample names should not contain \".\" apart from in their extension\n",
    "    e.g. Sample_1.fastq.gz is fine, but Sample.1.fastq.gz will result in difficulty in tracking individuals\n",
    "    through the pipeline. \n",
    "    \n",
    "    Incremental_U takes, as its only argument, a dictionary with the structure designated below. Copy and paste the\n",
    "    script below into a jupyter notebook cell or .py script and fill in the options according to your needs. \n",
    "    \n",
    "    \n",
    "    ## INPUT PARAMETERS HERE -----------------------------------------\n",
    "\n",
    "    parameters =          ## List, eg [\"M\", \"m\", \"MS\"]. Note** if only testing 1 param, this must still be a list e.g. [\"M\"]\n",
    "    M_vals =              ## List of integers, e.g. [1,2,3,4]\n",
    "    m_vals =              ## List of integers, e.g. [1,2,3,4]\n",
    "    MS_vals =             ## List of integers, e.g. [1,2,3,4]\n",
    "    threads =             ## Integer e.g. 7\n",
    "    parent_dir =          ## Absolute directory containing the demultiplexed raw read fasta/fastq files\n",
    "    run_cline_switch =    ## Integer - 1 to run stacks cline or 0 to run pipeline on existing outputs, without running stacks\n",
    "\n",
    "\n",
    "    ## Making input dictionary --------------------------------------\n",
    "\n",
    "    Setup_dict = {}\n",
    "    Setup_dict[\"parameters\"] = {}\n",
    "    Setup_dict[\"threads\"] = threads\n",
    "    Setup_dict[\"parent_directory\"] = parent_dir\n",
    "    Setup_dict[\"run_cline_switch\"] = run_cline_switch\n",
    "    Setup_dict[\"verbose\"] = False\n",
    "\n",
    "    for param in parameters:\n",
    "        if \"M\" in param:\n",
    "            Setup_dict[\"parameters\"][param] = M_vals\n",
    "        if \"m\" in param:\n",
    "            Setup_dict[\"parameters\"][param] = m_vals\n",
    "        if \"MS\" in param:\n",
    "            Setup_dict[\"parameters\"][param] = MS_vals\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    Master_dict = {} ## All outputs go in here!\n",
    "    \n",
    "    Master_dict['parent_directory'] = Setup_dict['parent_directory']\n",
    "    ## Finding the samples -----------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    file_formats = []\n",
    "\n",
    "    for i in os.listdir(Setup_dict[\"parent_directory\"]):\n",
    "        if i.endswith(\".fq_1\") or i.endswith(\".fq\") or i.endswith(\"1.fastq\"):\n",
    "            Master_dict[i] = {}\n",
    "            file_formats.append(\"fastq\")\n",
    "\n",
    "        elif i.endswith(\".fq_1.gz\") or i.endswith(\".fq.gz\") or i.endswith(\"1.fastq.gz\"):\n",
    "            Master_dict[i] = {}\n",
    "            file_formats.append(\"gzfastq\")\n",
    "    \n",
    "    ## Checking file formats are ok --------------------------------------------------------------------------------------------\n",
    "\n",
    "    file_formats = list(set(file_formats))\n",
    "\n",
    "    if len(file_formats) > 1:\n",
    "        sys.exit(\"Inconsistent file format, please make sure all files are of the same format\")\n",
    "    else:\n",
    "        file_format = file_formats[0]\n",
    "            \n",
    "            \n",
    "    # making the structure of the master dictionary --------------------------------------------------------------------------\n",
    "    for parameter in Setup_dict[\"parameters\"]:\n",
    "        for sample in Master_dict:\n",
    "            if sample.endswith(\"fq\") or sample.endswith(\"gz\"):\n",
    "                Master_dict[sample][parameter] = {}\n",
    "                for value in Setup_dict[\"parameters\"][parameter]:\n",
    "                    Master_dict[sample][parameter][value] = {}\n",
    "                \n",
    "    print \"\\n##### ------- Test samples, parameters and values ------ #####\\n\"\n",
    "    pp = pprint.PrettyPrinter(indent=2)\n",
    "    pp.pprint(Master_dict)\n",
    "\n",
    "\n",
    "    ## Making the directories and the command line scripts and run them -------------------------------------------------------\n",
    "    \n",
    "    run_cline = Setup_dict[\"run_cline_switch\"]\n",
    "    \n",
    "    if not run_cline == 1:\n",
    "        print \"\\n ###### ------ Not running command lines ------ ###### \\n\"\n",
    "        \n",
    "    ID = 1\n",
    "    \n",
    "    \n",
    "    \n",
    "    for sample in Master_dict.keys():\n",
    "        if sample.endswith(\"fq\") or sample.endswith(\"gz\"):\n",
    "            sample_name = sample.split(\".\")[0]\n",
    "            test_params = Master_dict[sample].keys()\n",
    "\n",
    "\n",
    "            if file_format == \"gzfastqc\":\n",
    "                tags_file_name = \"%s.tags.tsv.gz\" % sample.split(\".\")[0]\n",
    "            else:\n",
    "                tags_file_name = \"%s.tags.tsv\" % sample.split(\".\")[0]\n",
    "\n",
    "\n",
    "            ## Making the necassary directories ---------------------------------------------------------------------------------\n",
    "\n",
    "            for param in Master_dict[sample]:\n",
    "\n",
    "                for val in Master_dict[sample][param]:\n",
    "\n",
    "                    dirname = '%s%s/%s_tests/%s_%i'%(Setup_dict[\"parent_directory\"],sample_name,param,param,val)\n",
    "                    #print dirname\n",
    "                    if not os.path.exists(dirname):\n",
    "                        try:\n",
    "                            os.makedirs(dirname)\n",
    "                        except:\n",
    "                            os.mkdir(dirname)\n",
    "\n",
    "                    ## Making and run the command lines for the sample ------------------------------------------------------\n",
    "                    \n",
    "                    cline = make_and_run_command_line(param, val, Setup_dict[\"parent_directory\"], sample, file_format, Setup_dict[\"threads\"], ID, run_cline)\n",
    "                    \n",
    "                    if run_cline == 1:\n",
    "                        if Setup_dict[\"verbose\"] == True:\n",
    "                            print \"Running Stacks command: %s\" % cline\n",
    "\n",
    "                    for root, dirs, files in os.walk(Setup_dict[\"parent_directory\"]):\n",
    "                        for fil in files:\n",
    "                            if \"tags.tsv\" in fil and sample_name in fil and \"%s_%s\" % (param, val) in root:\n",
    "\n",
    "                                if param in Master_dict[sample]:\n",
    "                                    if val in Master_dict[sample][param]:\n",
    "                                        tagsfilepath = \"%s/%s\" % (root, fil)\n",
    "\n",
    "                                  we      ## Looking at the blacklisting ----------------------------------------------------------\n",
    "\n",
    "                                        Master_dict[sample][param][val][\"blacklists\"] = {} \n",
    "                                        Master_dict[sample][param][val][\"blacklists\"][\"bl_lumbers\"], Master_dict[sample][param][val][\"blacklists\"][\"bl_multistak\"], Master_dict[sample][param][val][\"blacklists\"][\"dl_lumbs\"], Master_dict[sample][param][val][\"blacklists\"][\"dl_multistak\"], Master_dict[sample][param][val][\"blacklists\"][\"dl_bl_multistak\"] = blacklister(tagsfilepath, Setup_dict[\"verbose\"])\n",
    "\n",
    "                                        ## Counting the number of tags ----------------------------------------------------------\n",
    "\n",
    "                                        Master_dict[sample][param][val][\"N_tags\"] = Tag_counter(tagsfilepath, param, val, Setup_dict[\"verbose\"])\n",
    "\n",
    "\n",
    "                                        ## Counting the coverage ------------------------------------------------------------------\n",
    "\n",
    "                                        Master_dict[sample][param][val][\"Coverage\"] = coverage_counter(tagsfilepath, Setup_dict[\"verbose\"])\n",
    "\n",
    "\n",
    "            ID += 1  ## INCREMENT the ID for the next sample\n",
    "    \n",
    "    \n",
    "    #------------------------------------------------------------------------------------------------------------------------------\n",
    "    ### Plotting the outputs ## ---------------------------------------------------------------------------------------------------\n",
    "    #------------------------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    print \"\\n               ##### PLOTTING #####                 \\n\"\n",
    "\n",
    "    ## Number of tags -----------------------------------------------\n",
    "    \n",
    "    Tag_plotter(Master_dict)\n",
    "    \n",
    "    \n",
    "    ## Coverage -----------------------------------------------------\n",
    "    \n",
    "    Coverage_plotter(Master_dict)\n",
    "     \n",
    "\n",
    "    return Master_dict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Getting sample names and IDs:\n",
    "\n",
    "wd = \"%s/%s\" % (working_directory, \"Incremental_tests/\")\n",
    "                \n",
    "def Get_sample_IDs(directory, verbose = True):\n",
    "    \"\"\" \n",
    "    Gets sample IDs from tags.tsv files in a directory\n",
    "    \n",
    "    \"\"\"             \n",
    "    sample_info = {}\n",
    "    for root, dirs, samples in os.walk(directory):\n",
    "        for sample in samples:\n",
    "            if \"tags.tsv\" in sample:\n",
    "\n",
    "                sample_prefix = sample.split(\".\")[0]\n",
    "\n",
    "                if not sample_prefix in sample_info:\n",
    "                    if sample.endswith(\"gz\"):\n",
    "                        sample_file = gzip.open(\"%s/%s\" % (root, sample))\n",
    "                    else:\n",
    "                        sample_file = open(\"%s/%s\" % (root, sample))\n",
    "                    for line in sample_file.readlines()[:10]:\n",
    "                        if \"consensus\" in line:\n",
    "                            sample_ID = line.split()[1]\n",
    "\n",
    "                            sample_info[sample_prefix] = sample_ID\n",
    "                            \n",
    "    if verbose == True:\n",
    "        for sample in sample_info:\n",
    "            print \"%s, ID = %s\" % (sample, sample_info[sample])\n",
    "        \n",
    "    return sample_info\n",
    "                        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pper_489, ID = 6\n",
      "Pper_R506, ID = 2\n",
      "Pper_490, ID = 3\n",
      "Pper_387, ID = 10\n",
      "Pper_156, ID = 7\n",
      "Pper_55, ID = 9\n",
      "Pper_30B, ID = 4\n",
      "Pper_506, ID = 5\n",
      "Pper_501, ID = 8\n",
      "Pper_88, ID = 1\n"
     ]
    }
   ],
   "source": [
    "ids = Get_sample_IDs(wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/djeffrie/Data/RADseq/Rdal_test//Incremental_tests/\n",
      "{ 'parameters': { 'M': [2, 3, 4, 5, 6], 'MS': [2, 3, 4], 'm': [2, 3, 4, 5, 6]},\n",
      "  'parent_directory': '/home/djeffrie/Data/RADseq/Rdal_test//Incremental_tests/',\n",
      "  'run_cline_switch': 0,\n",
      "  'threads': 7,\n",
      "  'verbose': True}\n"
     ]
    }
   ],
   "source": [
    "## INPUT INCREMENTAL PARAMETERS HERE -----------------------------------------\n",
    "\n",
    "working_directory = \"/home/djeffrie/Data/RADseq/Rdal_test/\"\n",
    "\n",
    "parameters = [\"M\", \"m\", \"MS\"]                                             ## List, eg [\"M\", \"m\", \"MS\"]. If only testing 1 param, this must still be a list e.g. [\"M\"]\n",
    "M_vals =   [2,3,4,5,6]                                              ## List, eg range(1,5,1) this would give [1,2,3,4]\n",
    "m_vals =   [2,3,4,5,6]                                              ## List, eg range(1,5,1) this would give [1,2,3,4]\n",
    "MS_vals =  [2,3,4]                                                 ## List, eg range(1,5,1) this would give [1,2,3,4]\n",
    "threads =  7                                                        ## Int. eg 7\n",
    "parent_dir = \"%s/%s\" % (working_directory, \"Incremental_tests/\" )    ## Absolute Dir containing the demultiplexed raw read fasta/fastq files\n",
    "run_cline_switch = 0                                             ## to switch on (1) to run stacks cline or off (0) to run pipeline on existing outputs\n",
    "\n",
    "print parent_dir\n",
    "\n",
    "## Making input dictionary --------------------------------------\n",
    "\n",
    "Setup_dict = {}\n",
    "Setup_dict[\"parameters\"] = {}\n",
    "Setup_dict[\"threads\"] = threads\n",
    "Setup_dict[\"parent_directory\"] = parent_dir\n",
    "Setup_dict[\"run_cline_switch\"] = run_cline_switch\n",
    "Setup_dict[\"verbose\"] = True\n",
    "\n",
    "for param in parameters:\n",
    "    if \"M\" in param:\n",
    "        Setup_dict[\"parameters\"][param] = M_vals\n",
    "    if \"m\" in param:\n",
    "        Setup_dict[\"parameters\"][param] = m_vals\n",
    "    if \"MS\" in param:\n",
    "        Setup_dict[\"parameters\"][param] = MS_vals\n",
    "        \n",
    "pp = pprint.PrettyPrinter(indent=2)\n",
    "pp.pprint(Setup_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
