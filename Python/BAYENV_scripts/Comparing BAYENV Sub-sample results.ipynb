{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First make a dictionary of (Run : list of top 1% markers)\n",
    "- Get file list\n",
    "- Unzip\n",
    "- Find top 1% \n",
    "- Get stacks Id's\n",
    "- Put in Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "from pandas import DataFrame as df\n",
    "import gzip\n",
    "from pprint import pprint as pp\n",
    "from collections import Counter as count\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Function to find top 1% in a BAYENV output file \n",
    "\n",
    "def Top_loc_finder(bf_file): \n",
    "    #print bf_file\n",
    "    bfs = df.from_csv(bf_file, header = -1, sep = '\\t')\n",
    "    del bfs[2]\n",
    "    cutoff_BF = bfs[1].quantile(0.95)  ## Change cutt off with this line!\n",
    "    top_1_bfs = bfs[bfs[1] > cutoff_BF]\n",
    "    #print top_1_bfs\n",
    "    \n",
    "    ### Now get stacks IDs for these (all in Loc_Keys.txt files in same path as bf_ files\n",
    "    \n",
    "    Key_file_path = bf_file.rpartition(\"/\")[0]\n",
    "    Keys_file = gzip.open(Key_file_path+\"/\"+\"Loc_keys.txt.gz\", 'r').readlines()\n",
    "    Keys_file = [i.split() for i in Keys_file]\n",
    "    \n",
    "    Stacks_IDs = []\n",
    "    for locus in Keys_file: ## subset for testing\n",
    "        for BAYENV_ID in list(top_1_bfs.index):\n",
    "            BAYENV_ID = BAYENV_ID.rpartition(\"/\")[2]\n",
    "            if BAYENV_ID == locus[1]:\n",
    "                Stacks_IDs.append(locus[0])\n",
    "    return Stacks_IDs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##1. First get list of files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bf_file_list = []\n",
    "for root, dirs, files in os.walk(\"/media/dan/34D5D1CE642D7E36/2013076_Hanfling_Bernd/BAYENV/Sub-samples/OUTPUTS/\"):\n",
    "    for my_file in files:\n",
    "        if my_file.startswith(\"bf_environ\"):\n",
    "            bf_file_list.append(root+\"/\"+my_file)\n",
    "            #print root+\"/\"+my_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##2. Loop over all directories and put top 1% in structured dictionary for each N-bottlenecked class, Sub-sample and replicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 3_bottlenecked_pops rep_1\n",
      "Done 3_bottlenecked_pops rep_0\n",
      "Done 3_bottlenecked_pops rep_3\n",
      "Done 3_bottlenecked_pops rep_2\n",
      "Done 3_bottlenecked_pops rep_5\n",
      "Done 3_bottlenecked_pops rep_4\n",
      "Done 3_bottlenecked_pops rep_7\n",
      "Done 3_bottlenecked_pops rep_6\n",
      "Done 7_bottlenecked_pops rep_1\n",
      "Done 7_bottlenecked_pops rep_0\n",
      "Done 7_bottlenecked_pops rep_3\n",
      "Done 7_bottlenecked_pops rep_2\n",
      "Done 7_bottlenecked_pops rep_5\n",
      "Done 7_bottlenecked_pops rep_4\n",
      "Done 1_bottlenecked_pops rep_1\n",
      "Done 1_bottlenecked_pops rep_3\n",
      "Done 1_bottlenecked_pops rep_2\n",
      "Done 1_bottlenecked_pops rep_5\n",
      "Done 1_bottlenecked_pops rep_4\n",
      "Done 1_bottlenecked_pops rep_7\n",
      "Done 1_bottlenecked_pops rep_6\n",
      "Done 2_bottlenecked_pops rep_1\n",
      "Done 2_bottlenecked_pops rep_0\n",
      "Done 2_bottlenecked_pops rep_3\n",
      "Done 2_bottlenecked_pops rep_2\n",
      "Done 2_bottlenecked_pops rep_5\n",
      "Done 2_bottlenecked_pops rep_4\n",
      "Done 2_bottlenecked_pops rep_7\n",
      "Done 2_bottlenecked_pops rep_6\n",
      "Done 5_bottlenecked_pops rep_1\n",
      "Done 5_bottlenecked_pops rep_0\n",
      "Done 5_bottlenecked_pops rep_3\n",
      "Done 5_bottlenecked_pops rep_2\n",
      "Done 5_bottlenecked_pops rep_5\n",
      "Done 5_bottlenecked_pops rep_4\n",
      "Done 5_bottlenecked_pops rep_7\n",
      "Done 5_bottlenecked_pops rep_6\n",
      "Done 4_bottlenecked_pops rep_1\n",
      "Done 4_bottlenecked_pops rep_0\n",
      "Done 4_bottlenecked_pops rep_3\n",
      "Done 4_bottlenecked_pops rep_2\n",
      "Done 4_bottlenecked_pops rep_5\n",
      "Done 4_bottlenecked_pops rep_4\n",
      "Done 4_bottlenecked_pops rep_7\n",
      "Done 4_bottlenecked_pops rep_6\n",
      "Done 6_bottlenecked_pops rep_1\n",
      "Done 6_bottlenecked_pops rep_0\n",
      "Done 6_bottlenecked_pops rep_3\n",
      "Done 6_bottlenecked_pops rep_2\n",
      "Done 6_bottlenecked_pops rep_5\n",
      "Done 6_bottlenecked_pops rep_4\n",
      "Done 6_bottlenecked_pops rep_7\n",
      "Done 6_bottlenecked_pops rep_6\n"
     ]
    }
   ],
   "source": [
    "## Get the data into a dictionary\n",
    "\n",
    "Top_loci = {}\n",
    "for bf_file in bf_file_list: ## subset for testing\n",
    "    #print bf_file\n",
    "    Bottled_class = bf_file.rpartition(\"/\")[0].rpartition(\"/\")[0].rpartition(\"/\")[2]\n",
    "    Sub_sample_numb = bf_file.rpartition(\"/\")[0].rpartition(\"/\")[2]\n",
    "    rep_numb = bf_file.rpartition(\"/\")[2][-5]\n",
    "    \n",
    "    ## creat multi-levelled dictionary {Top_loci: {Numb bottlencecked pops:{Sub sample:{replicate: [Top loci stacks ids]}}}}\n",
    "    if Bottled_class not in Top_loci.keys():\n",
    "        Top_loci[Bottled_class] = {}\n",
    "    if Sub_sample_numb not in Top_loci[Bottled_class].keys():\n",
    "        Top_loci[Bottled_class][Sub_sample_numb] = {}\n",
    "    if rep_numb not in Top_loci[Bottled_class][Sub_sample_numb].keys():\n",
    "        Top_loci[Bottled_class][Sub_sample_numb][rep_numb] = []\n",
    "    \n",
    "    \n",
    "    Top_loci[Bottled_class][Sub_sample_numb][rep_numb] = Top_loc_finder(bf_file)\n",
    "     \n",
    "#pp(Top_loci)\n",
    "\n",
    "## Now find loci in top 1% in 3 out of 5 replicates\n",
    "\n",
    "for Bottlenecked_class in Top_loci.keys():\n",
    "    for Sub_sample in Top_loci[Bottlenecked_class].keys():\n",
    "        all_reps = Top_loci[Bottlenecked_class][Sub_sample].values()\n",
    "        merged = [locus for replicate in all_reps for locus in replicate]\n",
    "        print \"Done\", Bottlenecked_class, Sub_sample\n",
    "        #print sorted(merged)\n",
    "        Top_loci[Bottlenecked_class][Sub_sample][\"Sub_sample_loc_counts\"] = count(merged)\n",
    "        \n",
    "        #print Top_loci[Bottlenecked_class][Sub_sample][\"Sub_sample_loc_counts\"]\n",
    "#pp(Top_loci)\n",
    "        \n",
    "## So now I have counts of loci that are in the top 1% of each replicate in each sub-sample.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Then see how many of these are shared with the Master analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Get list of loci that are in top 1% of 3/5 the Master replicates\n",
    "\n",
    "Master_counts = {}\n",
    "master_count_file = open(\"/media/dan/34D5D1CE642D7E36/2013076_Hanfling_Bernd/BAYENV/Sub-samples/MASTER_npops_17/MASTER_winners_5percent.tsv\", 'w')\n",
    "for root, dirs, files in os.walk(\"/media/dan/34D5D1CE642D7E36/2013076_Hanfling_Bernd/BAYENV/Sub-samples/MASTER_npops_17/\"):\n",
    "    for master_file in files:\n",
    "        if master_file.startswith(\"bf_environ\"):\n",
    "            Master_counts[master_file] = Top_loc_finder(root+\"/\"+master_file)\n",
    "                         \n",
    "            \n",
    "## Now, make a list of loci in 3/5 replicates\n",
    "all_winners = count([locus for replicate in Master_counts.values() for locus in replicate])\n",
    "\n",
    "for locus in all_winners:\n",
    "    master_count_file.write(locus+\"\\n\")\n",
    "master_count_file.close()\n",
    "                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Master_winners = []\n",
    "for loc in all_winners.items():\n",
    "    if loc[1] >= 3:\n",
    "        Master_winners.append(loc[0])\n",
    "#print Master_winners\n",
    "#Master_winners.append('3733') ## test to make sure it works\n",
    "\n",
    "Shared_winners = []\n",
    "for Bottlenecked_class in Top_loci.keys():\n",
    "    for Sub_sample in Top_loci[Bottlenecked_class].keys():\n",
    "        for top_locus in Top_loci[Bottlenecked_class][Sub_sample][\"Sub_sample_loc_counts\"].items():\n",
    "            if top_locus[1] >= 3  and top_locus[0] in Master_winners: ## If the locus came up in 3 or more replicates within a subsample and is shared with the master analysis\n",
    "                Shared_winners.append([Bottlenecked_class, Sub_sample, top_locus[0]])\n",
    "#for shared_winner in Shared_winners:\n",
    " #   print shared_winner\n",
    "\n",
    "\n",
    "Shared_winners_file = open(\"/media/dan/34D5D1CE642D7E36/2013076_Hanfling_Bernd/BAYENV/Sub-samples/Shared_BAYENV_winners_5_percent.tsv\", 'w')\n",
    "    \n",
    "Shared_winners_df = df(Shared_winners)\n",
    "Shared_winners_df.to_csv(Shared_winners_file, sep=\"\\t\", header = [\"Number of Btld pops per subsample\", \"Sub_sample\", \"Shared winning locus StacksID\"])\n",
    "\n",
    "\n",
    "Shared_winners_file.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "3733"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
