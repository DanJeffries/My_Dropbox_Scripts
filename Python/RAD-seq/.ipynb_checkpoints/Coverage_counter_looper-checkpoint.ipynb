{
 "metadata": {
  "name": "",
  "signature": "sha256:c65d7a848a81dc75de0b452759da4cf450f74701866078b568e469cbfd1a5d7e"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Coverage Counter, to iterate over tsv files in subdirectories and produce histograms of coverage"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np ## Put the imports in here because, for some reason, have to import them each time a new kernel starts, or the plots are plotted over eachother\n",
      "import collections\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "import matplotlib.pylab as py\n",
      "import os\n",
      "import csv\n",
      "\n",
      "def coverage_counter(file_name):\n",
      "    csvcol3 = []\n",
      "    csvfile = open(file_name, 'rb')\n",
      "    csvread = csv.reader(csvfile, delimiter =\"\\t\") ## read csv in\n",
      "    \n",
      "    for line in csvread:\n",
      "        csvcol3.append(int(line[2])) ## add the 3 column of each line to a list\n",
      "    csvcol3 = [int(i) for i in csvcol3] ## convert this list of integers to strings\n",
      "    \n",
      "    coverage_count = collections.Counter()\n",
      "    for tagID in csvcol3:\n",
      "        coverage_count[tagID] += 1 ## count the number of times each tag ID occurs (i.e. the coverage)\n",
      "    \n",
      "    coverage_values = []\n",
      "    f = open(str(file_name[:-9]+\" Coverage data.txt\"), 'a') ## make a new txt file for coverage data\n",
      "    \n",
      "    for i,j in coverage_count.iteritems():\n",
      "        coverage_values.append(j) ## append the coverage to a list\n",
      "        f.write(str(j) + \"\\n\") ## write the coverage data to the txt file\n",
      "    \n",
      "    plt.hist(coverage_values, bins = max(coverage_values),range = [0, 100])\n",
      "    plt.hist(coverage_values, bins = max(coverage_values),range = [0, 100])\n",
      "    plt.title(file_name[2:8]+file_name[27:33])\n",
      "    plt.xlabel(\"Coverage\")\n",
      "    plt.ylabel(\"Frequency\")\n",
      "    plt.text(60, 1200, \"Mean tag coverage =\"+ str(np.round(np.mean(coverage_values),2)))\n",
      "    plt.savefig(file_name.rpartition('/')[0]+\"/Coverage.pdf\")\n",
      "    plt.close()\n",
      "    \n",
      "    f.close()\n",
      "    print coverage_values[:10]\n",
      "\n",
      "    ## look into the ggplot2 module for python to make a nicer looking graph\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Coverage_counter_looper(): Loops over the parent directory given with coverage counter \n",
      "- calculates the coverage per tag, for each sample and incrementation\n",
      "- makes a histogram per sample and increment and puts it in the respective folder\n",
      "- makes the coverage multiplot and puts it in the parent directory\n",
      "- prints the first 10 coverage values as a test that its working\n",
      "- prints the coverage data to a file for any further use\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def coverage_counter_looper(directory): ## make sure this is the right parent directory - i.e. contains the sample name folder created by increMental\n",
      "    tsvs = []\n",
      "    subdirs = []\n",
      "    cov_files = []\n",
      "    \n",
      "    ## Make a list of the files, including their paths from the current directory\n",
      "    \n",
      "    for root, dirs, files in os.walk(str(directory)):\n",
      "        for fil in files:\n",
      "            if fil.endswith(\".tags.tsv\"):\n",
      "                tsvs.append(str(str(root)+'/'+str(fil)))\n",
      "                subdirs.append(str(str(root)+'/'+str(dirs)))\n",
      "                \n",
      "    \n",
      "    ## Execute coverage counter for all these files\n",
      "    \n",
      "    for tsv in tsvs:\n",
      "        coverage_counter(tsv)           \n",
      "    \n",
      "    ## make the multiplot\n",
      "    \n",
      "    for root, dirs, files in os.walk(str(directory)):\n",
      "        for fil in files:\n",
      "            if fil.endswith(\"data.txt\"):\n",
      "                cov_files.append(str(str(root)+'/'+str(fil)))\n",
      "    \n",
      "    plot_number = 1\n",
      "\n",
      "    fig = plt.figure()\n",
      "    plt.subplots_adjust(hspace = 0.8)\n",
      "\n",
      "    for cov_file in cov_files:    \n",
      "        data_file = open(cov_file, 'r')\n",
      "        data = [int(i) for i in data_file.readlines()]\n",
      "    \n",
      "        fig.add_subplot(np.round((len(cov_files)/3)+1),3,plot_number)\n",
      "        plt.hist(data, bins = 100,range = [0, 150])\n",
      "        plt.title(cov_file.split('/')[1].partition('_')[0]+\" \"+ cov_file.split('/')[3], fontsize = 5)\n",
      "        py.yticks(fontsize = 5)\n",
      "        py.xticks(fontsize = 5)\n",
      "        plt.xlabel(\"Coverage\", fontsize = 5)\n",
      "        plt.ylabel(\"Frequency\", fontsize = 5)\n",
      "        plt.text(60, 1200, \"Mean tag coverage =\"+ str(np.round(float(np.mean(data)),2)), fontsize = 5)\n",
      "    \n",
      "        plot_number += 1\n",
      "\n",
      "    plt.savefig('./coverage_multiplot.pdf')    \n",
      "    plt.close('all')\n",
      "    \n",
      "    \n",
      "    print('number of coverage plots = '+ str(plot_number -1))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      " path.split('/')[1].partition('_')[0]+ \" \" + path.split('/')[3] ## dont know what this but is"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Note the font and line width sizes on the histograms are a bit messy, if I am trying to make this more polished I can make the relative to the number of plots quite easily."
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Plotting coverage per sample\n",
      "-Take the coverage files outputted by coverage looper, and produces graphs for each sample\n",
      "\n",
      "** Note that the range values for scatters have to be manually inputted and must be the same as the parameter range values used in IncreMental**"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "coverage_counter_looper('./')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[10, 8, 23, 15, 16, 8, 17, 14, 15, 10]\n",
        "[346, 266, 71, 986, 1238, 71, 137, 1751, 341, 214]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[30, 20, 26, 35, 20, 14, 22, 16, 32, 42]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[20, 18, 40, 13, 26, 8, 15, 24, 27, 24]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[17, 13, 12, 12, 25, 19, 10, 17, 15, 10]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[12, 11, 20, 19, 26, 21, 9, 12, 24, 16]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[346, 266, 71, 986, 1238, 71, 137, 1751, 341, 214]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[19, 8, 12, 15, 16, 24, 18, 14, 18, 21]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[11, 20, 14, 13, 16, 11, 19, 14, 14, 14]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[14, 29, 33, 15, 14, 13, 21, 17, 36, 13]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[14, 11, 15, 19, 17, 28, 14, 28, 17, 18]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[20, 46, 38, 33, 33, 13, 19, 35, 27, 35]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[13, 21, 15, 17, 12, 15, 13, 17, 10, 25]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[25, 11, 19, 21, 29, 23, 36, 16, 25, 10]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[18, 15, 14, 40, 20, 16, 19, 19, 22, 29]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[16, 32, 11, 15, 27, 16, 14, 18, 11, 14]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[33, 9, 38, 27, 47, 34, 41, 51, 37, 35]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[13, 26, 15, 26, 18, 44, 26, 24, 55, 56]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[51, 58, 36, 32, 36, 14, 49, 37, 51, 43]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[42, 43, 43, 36, 49, 39, 38, 21, 41, 51]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[10, 24, 31, 44, 24, 34, 33, 36, 38, 39]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[50, 12, 31, 39, 19, 41, 49, 17, 12, 36]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[44, 28, 9, 39, 33, 43, 54, 11, 35, 18]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[27, 101, 52, 29, 24, 22, 51, 28, 20, 48]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "number of coverage plots = 24"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sample_coverage = []\n",
      "sample_names = []\n",
      "cov_data = []\n",
      "cov_values = []\n",
      "\n",
      "## Define a cool little helper function for \"natural sorting\". (no idea how it works though!)\n",
      "\n",
      "import re\n",
      "def natural_key(string_): \n",
      "    return [int(s) if s.isdigit() else s for s in re.split(r'(\\d+)', string_)]\n",
      "\n",
      "## get file names and paths\n",
      "\n",
      "for root, dirs, files in os.walk(str('./')):\n",
      "    for fil in files:\n",
      "        if fil.endswith(\"data.txt\"):\n",
      "            data_file = open(str(root+'/'+fil), 'r')\n",
      "            data = [int(i) for i in data_file.readlines()]\n",
      "            sample_coverage.append(fil.partition('_')[0] + \"__\" + root.split('/')[3]+\"\\t\"+ str(np.round(np.mean(data),2)))\n",
      "\n",
      "## make a list of uniq sample names\n",
      "\n",
      "for i in sample_coverage:\n",
      "    sample_names.append(i.split('\\t')[0].partition('_')[0])\n",
      "sample_names = set(sample_names)\n",
      "print \"sample names =\" \n",
      "print sample_names\n",
      "\n",
      "## Use this list to separate the data according to the sample it comes from\n",
      "## And then plot the graphs in one file and save in parent directory\n",
      "\n",
      "fig = plt.figure() ## make fig\n",
      "plt.subplots_adjust(hspace = 0.5) ## adjust subplots\n",
      "plot_number =1\n",
      "for name in sample_names: ## for each sample\n",
      "    for line in sample_coverage:\n",
      "        if name in line:\n",
      "            cov_data.append(line)\n",
      "    cov_data = sorted(cov_data, key = natural_key) ## sort \"naturally\"\n",
      "    for i in cov_data:\n",
      "        cov_values.append(float(i.split()[1]))\n",
      "    print name\n",
      "    print cov_values\n",
      "    \n",
      "## And now plot the graphs as subplots in a main fig. Put in parent dir.   \n",
      "    \n",
      "    fig.add_subplot(np.round((len(sample_names)/2)+1),2,plot_number)\n",
      "    plt.scatter(range(0,16,2),cov_values) ## Manually input range from IncreMental here!\n",
      "    plt.plot(range(0,16,2),cov_values)\n",
      "    plt.title(name+\" coverage per tag with incrementation\", fontsize = 10)\n",
      "    plt.xlabel(\"Ustacks Parameter Value\", fontsize = 10)\n",
      "    plt.ylabel(\"Coverage per tag\", fontsize = 10)\n",
      "    plt.xticks(fontsize = 7)\n",
      "    plt.yticks(fontsize = 7)\n",
      "    \n",
      "    cov_data = []\n",
      "    cov_values = []\n",
      "    plot_number+=1\n",
      "plt.savefig(\"mean_coverage_multiplot.pdf\")\n",
      "plt.close('all')    \n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "sample names =\n",
        "set(['CAKE10', 'HOLT10', 'GBP5'])\n",
        "CAKE10\n",
        "[44.07, 46.82, 47.88, 48.9, 49.8, 50.45, 50.88, 51.19]\n",
        "HOLT10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[22.56, 26.29, 28.32, 29.22, 29.63, 29.83, 29.98, 30.13]\n",
        "GBP5\n",
        "[25.36, 29.91, 31.08, 31.64, 32.01, 32.28, 32.48, 32.64]\n"
       ]
      }
     ],
     "prompt_number": 275
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## If I want to make just one plot from existing coverage data files:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plot_number = 1\n",
      "\n",
      "fig = plt.figure()\n",
      "plt.subplots_adjust(hspace = 1.2)\n",
      "\n",
      "cov_files = []    \n",
      "for root, dirs, files in os.walk(str('./')):\n",
      "    for fil in files:\n",
      "        if fil.endswith(\"data.txt\"):\n",
      "            cov_files.append(str(str(root)+'/'+str(fil)))\n",
      "\n",
      "for cov_file in cov_files:    \n",
      "    \n",
      "    data_file = open(cov_file, 'r')\n",
      "    data = [int(i) for i in data_file.readlines()]\n",
      "    \n",
      "    fig.add_subplot(np.round((len(cov_files)/3)+1),3,plot_number)\n",
      "    plt.hist(data, bins = 100,range = [0, 100])\n",
      "    plt.title(cov_file.split('/')[1].partition('_')[0]+\" \"+ cov_file.split('/')[3], fontsize = 5)\n",
      "    py.yticks(fontsize = 3)\n",
      "    py.xticks(fontsize = 3)\n",
      "    plt.xlabel(\"Coverage\", fontsize = 3)\n",
      "    plt.ylabel(\"Frequency\", fontsize = 3)\n",
      "    plt.text(60, 1200, \"Mean tag coverage =\"+ str(np.round(float(np.mean(data)),2)), fontsize = 3)\n",
      "\n",
      "    \n",
      "    plot_number += 1\n",
      "\n",
      "plt.savefig('./coverage_multiplot.pdf')    \n",
      "plt.close('all')\n",
      "    \n",
      "print(plot_number)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "25\n"
       ]
      }
     ],
     "prompt_number": 72
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## A good way to split path names for use in file saving - much more robust to different sample name lengths etc."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "path = './CAKE10_RD-P1-178_1/M_tests/M_0/CAKE10_RD-P1-178_1.tags.tsv'\n",
      "\n",
      "print(path.split('/')) ## gives a list of the delimited sections of the string\n",
      "\n",
      "print(path.partition('/'))## gives a list of everything BEFORE the FIRST occurance of the delimiter, the delimiter and everything left\n",
      "\n",
      "print(path.rpartition('/')[0]) ## gives a string of everything BEFORE the LAST occurance of delimiter - very good for file paths\n",
      "\n",
      "print(path.split('/')[1].partition('_')[0]+ \" \" + path.split('/')[3]) ## combined here"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['.', 'CAKE10_RD-P1-178_1', 'M_tests', 'M_0', 'CAKE10_RD-P1-178_1.tags.tsv']\n",
        "('.', '/', 'CAKE10_RD-P1-178_1/M_tests/M_0/CAKE10_RD-P1-178_1.tags.tsv')\n",
        "./CAKE10_RD-P1-178_1/M_tests/M_0\n",
        "CAKE10 M_0\n"
       ]
      }
     ],
     "prompt_number": 74
    }
   ],
   "metadata": {}
  }
 ]
}