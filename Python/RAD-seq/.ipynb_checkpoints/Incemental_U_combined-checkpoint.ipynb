{
 "metadata": {
  "name": "",
  "signature": "sha256:8ce1b310317dd2cd79b027ffdcc37a4201920ab23be936a2fb25ee7e11a2dbb4"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "import subprocess"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Define helper functions"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Define the bash file execution function"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def execute(bash_file):\n",
      "    f = open(str(bash_file), 'r')\n",
      "    script = f.read()\n",
      "    subprocess.call(script, shell=True)\n",
      "    print script"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def replace_all(text,dic): ## this function takes the string to be searched and a dictionary of replacements\n",
      "    for i, j in dic.iteritems(): #iteritems needed when using dic entries - remember this\n",
      "        text = text.replace(i,j) ## for each dictionary entry, replace the \"key\" with the \"value\" in the text\n",
      "    return text"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Define the incrementation function"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np ## Put the imports in here because, for some reason, have to import them each time a new kernel starts, or the plots are plotted over eachother\n",
      "import collections\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "import matplotlib.pylab as py\n",
      "import os\n",
      "import csv\n",
      "from collections import Counter\n",
      "import re\n",
      "\n",
      "\n",
      "def IncreMental_U(param, start_value, stop_value, increment, parent_dir_path, file_format, threads):\n",
      "## file_path file path to look for raw read .fastq files\n",
      "    \n",
      "    \n",
      "    ##lists and command templates \n",
      "    sample_names = [] \n",
      "    param_values = range(start_value, stop_value, increment)\n",
      "    \n",
      "    ID = 1 ## Assign a different ID to each individual with for a given param value\n",
      "    \n",
      "    for i in os.listdir(parent_dir_path):\n",
      "        if i.endswith(\"1.fastq\"): ## this next line is VERY IMPORTANT - its the one that I can use to specify what samples to use in the analysis!!\n",
      "            sample_names.append(i)\n",
      "    \n",
      "    print \"samples present\", sample_names\n",
      "    print (\"Parameter values =\" + str(param_values))\n",
      "    \n",
      "   \n",
      "    for sample in sample_names: ## so for each sample ...\n",
      "        Mcommand_list = []\n",
      "        Mcommand_list_final = []\n",
      "        param_value_list = []\n",
      "    ## if statement determines the parameter to increment\n",
      "\n",
      "        if param == 'M':\n",
      "            Mcommand = 'mkdir '+ str(sample[:-6])+ '/M_tests/M_x/; ustacks -t file_format -M x -m 6 -p threads -d -r -i '+str(ID)+' -f input_file -o '+ str(sample[:-6])+ '/M_tests/M_x/ ;\\n'\n",
      "            for value in param_values:\n",
      "                param_value_list.append(str(value))\n",
      "\n",
      "            ## -N left as default(M+2)\n",
      "            ## -m kept at 6\n",
      "            ## These can be iterated by modifying the Mcommand or mcommand, likewise -d and -r can be removed if needed\n",
      "        \n",
      "            ## for each parameter value, replace the 'x' with the value and add it to the list for the bash script\n",
      "            for value in param_value_list:\n",
      "                Mcommand_list.append(Mcommand.replace(\"x\", value))\n",
      "\n",
      "            ## replacing the rest of the script template with useful values:\n",
      "            ## define a dictionary of replacements - the keys are the strings to be replaced, the values are the replacements\n",
      "            reps = {\"file_format\":str(file_format), \"threads\":str(threads), \"input_file\": str(sample)}\n",
      "        \n",
      "            ## note that the values have to be strings for .replace to be able to use them, so str() must be used here\n",
      "        \n",
      "            ## use the replace all function to replace the template strings with usefer given values or strings \n",
      "            for Mcommand in Mcommand_list:\n",
      "                Mcommand_list_final.append(replace_all(Mcommand, reps))\n",
      "            \n",
      "            f = open(str(sample[:-6]+\"_Ustacks_commands.sh\"), 'w') ## .. make a bash script file in the current ipython directory...\n",
      "            f.write(\"#!/bin/bash\\n\\nmkdir \"+sample[:-6]+\"\\nmkdir \"+sample[:-6]+\"/M_tests/\\n\") ## .. append a few lines for directory management...\n",
      "            \n",
      "            for command in Mcommand_list_final:\n",
      "                f.write(command)\n",
      "            f.close()\n",
      "            \n",
      "            ID += 1 \n",
      "            execute(str(sample[:-6]+\"_Ustacks_commands.sh\")) ## Finally, excecute the file\n",
      "            \n",
      "            \n",
      "    \n",
      "        elif param == \"m\":\n",
      "            mcommand = 'mkdir '+ str(sample[:-6])+ '/m_tests/m_y/; ustacks -t file_format -M 3 -m y -p threads -d -r -i '+str(ID)+' -f input_file -o '+ str(sample[:-6])+ '/m_tests/m_y/ ;\\n'\n",
      "            for value in param_values:\n",
      "                param_value_list.append(str(value))\n",
      "     \n",
      "            for value in param_value_list:\n",
      "                mcommand_list.append(mcommand.replace(\"y\", value))\n",
      "\n",
      "            ## define a dictionary of replacements - the keys are the strings to be replaced, the values are the replacements\n",
      "            reps = {\"file_format\":str(file_format), \"threads\":str(threads), \"input_file\": str(sample)}\n",
      "            ## note that the values have to be strings for .replace to be able to use them, so str() is used here\n",
      "\n",
      "            for mcommand in mcommand_list:\n",
      "                mcommand_list_final.append(replace_all(mcommand, reps))\n",
      "            \n",
      "            f = open(str(sample[:-6]+\"_Ustacks_commands.sh\"), 'w') ## .. make a bash script file in the current ipython directory...\n",
      "            f.write(\"#!/bin/bash\\n\\nmkdir \"+sample[:-6]+\"\\nmkdir \"+sample[:-6]+\"/m_tests/\\n\") ## .. append a few lines for directory management...\n",
      "            \n",
      "            for command in Mcommand_list_final:\n",
      "                f.write(command)\n",
      "            f.close()\n",
      "                \n",
      "\n",
      "            ID += 1 \n",
      "            execute(str(sample[:-6]+\"_Ustacks_commands.sh\")) ## Finally, excecute the file\n",
      "            \n",
      "  ## TAG COUNTER ##         \n",
      "            \n",
      "    def Tag_counter(parent_dir_path):\n",
      "\n",
      "        c = Counter()\n",
      "        sample_names = []\n",
      "        tag_data = []\n",
      "        names = []\n",
      "    \n",
      "        ## Define a cool little helper function for \"natural sorting\". (no idea how it works though!)\n",
      "    \n",
      "        \n",
      "        def natural_key(string_): \n",
      "            return [int(s) if s.isdigit() else s for s in re.split(r'(\\d+)', string_)]\n",
      "    \n",
      "        ## Another cool function to count the length of a file\n",
      "    \n",
      "        def file_len(data):\n",
      "                for i, l in enumerate(data):\n",
      "                    pass\n",
      "                return i + 1\n",
      "    \n",
      "\n",
      "        ## get file names and paths\n",
      "        for root, dirs, files in os.walk(str(parent_dir_path)):\n",
      "            for fil in files:\n",
      "                if fil.endswith(\"tags.tsv\") and 'catalog' not in fil:\n",
      "                    data_file = open(str(root+'/'+fil), 'r')\n",
      "                    tag_tally = 0\n",
      "                    for line in data_file.readlines():\n",
      "                        if 'consensus' in line:\n",
      "                            tag_tally +=1\n",
      "                    tag_data.append(root.split('/')[1].partition('_')[0]+\"__\"+root.split('/')[3] + \"\\t\"+str(tag_tally)) ## works nicely just put this into a list with sample name and its nearly done\n",
      "        tag_data = sorted(tag_data, key = natural_key)\n",
      "        f = open(\"Tag_numbers.txt\", 'w')\n",
      "        for i in tag_data:\n",
      "            f.write(i+\"\\n\")\n",
      "        f.close()\n",
      "    \n",
      "        ## get the sample names\n",
      "        for i in tag_data:\n",
      "            names.append(i.split('\\t')[0].partition('_')[0])\n",
      "        names = set(names)\n",
      "    \n",
      "        ##plot the figures\n",
      "        fig = plt.figure()\n",
      "        plt.subplots_adjust(hspace = 0.5) ## adjust subplots\n",
      "        plot_number =1\n",
      "        for i in names:\n",
      "            tag_numbers = []\n",
      "            for item in tag_data:\n",
      "                if item.startswith(i):\n",
      "                    tag_numbers.append(int(item.split('\\t')[1]))\n",
      "            print \"TAG COUNTER\\n\", i, tag_numbers\n",
      "            fig.add_subplot(np.round((len(names)/2)+1),2,plot_number)\n",
      "            plt.scatter(range(start_value, stop_value, increment),tag_numbers) ## Manually input the same parameter range used in incremental IncreMental here for the x axis labels.\n",
      "            plt.plot(range(start_value, stop_value, increment),tag_numbers)\n",
      "            plt.title(i+\" Change in number of tags with incrementation\", fontsize = 5)\n",
      "            plt.xlabel(\"Ustacks Parameter Value\", fontsize = 10)\n",
      "            plt.ylabel(\"Number of tags\", fontsize = 10)\n",
      "            plt.xticks(fontsize = 7)\n",
      "            plt.yticks(fontsize = 7)\n",
      "        \n",
      "            tag_numbers = []\n",
      "            plot_number+=1\n",
      "        plt.savefig(\"Tags_per_sample.pdf\")\n",
      "        plt.close('all')  \n",
      "    \n",
      "    ## Use tag counter\n",
      "    \n",
      "    Tag_counter(parent_dir_path)\n",
      "\n",
      "    ## COVERAGE COUNTER ##\n",
      "    \n",
      "    def coverage_counter(file_name):\n",
      "        csvcol3 = []\n",
      "        csvfile = open(file_name, 'rb')\n",
      "        csvread = csv.reader(csvfile, delimiter =\"\\t\") ## read csv in\n",
      "    \n",
      "        for line in csvread:\n",
      "            csvcol3.append(int(line[2])) ## add the 3 column of each line to a list\n",
      "        csvcol3 = [int(i) for i in csvcol3] ## convert this list of integers to strings\n",
      "    \n",
      "        coverage_count = collections.Counter()\n",
      "        for tagID in csvcol3:\n",
      "            coverage_count[tagID] += 1 ## count the number of times each tag ID occurs (i.e. the coverage)\n",
      "    \n",
      "        coverage_values = []\n",
      "        f = open(str(file_name[:-9]+\" Coverage data.txt\"), 'a') ## make a new txt file for coverage data\n",
      "    \n",
      "        for i,j in coverage_count.iteritems():\n",
      "            coverage_values.append(j) ## append the coverage to a list\n",
      "            f.write(str(j) + \"\\n\") ## write the coverage data to the txt file\n",
      "    \n",
      "        plt.hist(coverage_values, bins = max(coverage_values),range = [0, 100])\n",
      "        plt.hist(coverage_values, bins = max(coverage_values),range = [0, 100])\n",
      "        plt.title(file_name[2:8]+file_name[27:33])\n",
      "        plt.xlabel(\"Coverage\")\n",
      "        plt.ylabel(\"Frequency\")\n",
      "        plt.text(60, 1200, \"Mean tag coverage =\"+ str(np.round(np.mean(coverage_values),2)))\n",
      "        plt.savefig(file_name.rpartition('/')[0]+\"/Coverage.pdf\")\n",
      "        plt.close()\n",
      "    \n",
      "        f.close()\n",
      "        print coverage_values[:10]\n",
      "        \n",
      "        ## COVERAGE COUNTER LOOPER ## \n",
      "        \n",
      "    def coverage_counter_looper(directory): ## make sure this is the right parent directory - i.e. contains the sample name folder created by increMental\n",
      "        tsvs = []\n",
      "        subdirs = []\n",
      "        cov_files = []\n",
      "    \n",
      "        ## Make a list of the files, including their paths from the current directory\n",
      "    \n",
      "        for root, dirs, files in os.walk(str(directory)):\n",
      "            for fil in files:\n",
      "                if fil.endswith(\".tags.tsv\") and 'catalog' not in fil:\n",
      "                    tsvs.append(str(str(root)+'/'+str(fil)))\n",
      "                    subdirs.append(str(str(root)+'/'+str(dirs)))\n",
      "                \n",
      "    \n",
      "        ## Execute coverage counter for all these files\n",
      "    \n",
      "        for tsv in tsvs:\n",
      "            coverage_counter(tsv)           \n",
      "    \n",
      "        ## make the multiplot\n",
      "        ## first get the coverage counter output files\n",
      "    \n",
      "        for root, dirs, files in os.walk(str(directory)):\n",
      "            for fil in files:\n",
      "                if fil.endswith(\"data.txt\") and 'catalog' not in fil:  ## have changed this so hopefully it doesn't pick up increMental_C outputs\n",
      "                    cov_files.append(str(str(root)+'/'+str(fil)))\n",
      "    \n",
      "        plot_number = 1\n",
      "\n",
      "        fig = plt.figure()\n",
      "        plt.subplots_adjust(hspace = 0.8)\n",
      "\n",
      "        for cov_file in cov_files:    \n",
      "            data_file = open(cov_file, 'r')\n",
      "            data = [int(i) for i in data_file.readlines()]\n",
      "    \n",
      "            fig.add_subplot(np.round((len(cov_files)/3)+1),3,plot_number)\n",
      "            plt.hist(data, bins = 100,range = [0, 150])\n",
      "            plt.title(cov_file.split('/')[1].partition('_')[0]+\" \"+ cov_file.split('/')[3], fontsize = 5)\n",
      "            py.yticks(fontsize = 5)\n",
      "            py.xticks(fontsize = 5)\n",
      "            plt.xlabel(\"Coverage\", fontsize = 5)\n",
      "            plt.ylabel(\"Frequency\", fontsize = 5)\n",
      "            plt.text(60, 1200, \"Mean tag coverage =\"+ str(np.round(float(np.mean(data)),2)), fontsize = 5)\n",
      "    \n",
      "            plot_number += 1\n",
      "\n",
      "        plt.savefig('./coverage_multiplot.pdf')    \n",
      "        plt.close('all')\n",
      "    \n",
      "    \n",
      "        print('number of coverage plots = '+ str(plot_number -1))\n",
      "    \n",
      "        ### Make the change-in average coverage plot\n",
      "    \n",
      "        sample_coverage = []\n",
      "        sample_names = []\n",
      "        cov_data = []\n",
      "        cov_values = []\n",
      "\n",
      "        ## Define a cool little helper function for \"natural sorting\". (no idea how it works though!)\n",
      "\n",
      "        import re\n",
      "        def natural_key(string_): \n",
      "            return [int(s) if s.isdigit() else s for s in re.split(r'(\\d+)', string_)]\n",
      "\n",
      "        ## get file names and paths\n",
      "\n",
      "        for root, dirs, files in os.walk(str('./')):\n",
      "            for fil in files:\n",
      "                if fil.endswith(\"data.txt\"):\n",
      "                    data_file = open(str(root+'/'+fil), 'r')\n",
      "                    data = [int(i) for i in data_file.readlines()]\n",
      "                    sample_coverage.append(fil.partition('_')[0] + \"__\" + root.split('/')[3]+\"\\t\"+ str(np.round(np.mean(data),2)))\n",
      "\n",
      "        ## make a list of uniq sample names\n",
      "\n",
      "        for i in sample_coverage:\n",
      "            sample_names.append(i.split('\\t')[0].partition('_')[0])\n",
      "        sample_names = set(sample_names)\n",
      "        print \"sample names =\" \n",
      "        print sample_names\n",
      "\n",
      "        ## Use this list to separate the data according to the sample it comes from\n",
      "        ## And then plot the graphs in one file and save in parent directory\n",
      "    \n",
      "        fig = plt.figure() ## make fig\n",
      "        plt.subplots_adjust(hspace = 0.5) ## adjust subplots\n",
      "        plot_number =1\n",
      "        for name in sample_names: ## for each sample\n",
      "            for line in sample_coverage:\n",
      "                if name in line:\n",
      "                    cov_data.append(line)\n",
      "            cov_data = sorted(cov_data, key = natural_key) ## sort \"naturally\"\n",
      "            for i in cov_data:\n",
      "                cov_values.append(float(i.split()[1]))\n",
      "            print name\n",
      "            print cov_values\n",
      "    \n",
      "        ## And now plot the graphs as subplots in a main fig. Put in parent dir.   \n",
      "    \n",
      "            fig.add_subplot(np.round((len(sample_names)/2)+1),2,plot_number)\n",
      "            plt.scatter(range(start_value, stop_value, increment),cov_values) ## Manually input range from IncreMental here!\n",
      "            plt.plot(range(start_value, stop_value, increment),cov_values)\n",
      "            plt.title(name+\" coverage per tag with incrementation\", fontsize = 10)\n",
      "            plt.xlabel(\"Ustacks Parameter Value\", fontsize = 10)\n",
      "            plt.ylabel(\"Coverage per tag\", fontsize = 10)\n",
      "            plt.xticks(fontsize = 7)\n",
      "            plt.yticks(fontsize = 7)\n",
      "    \n",
      "            cov_data = []\n",
      "            cov_values = []\n",
      "            plot_number+=1\n",
      "        plt.savefig(\"mean_coverage_multiplot.pdf\")\n",
      "        plt.close('all')\n",
      "    \n",
      "    coverage_counter_looper(parent_dir_path)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 44
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "IncreMental_U('M', 0, 6, 2, './', 'fastq', 8)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "samples present ['GF10_RD-P1-104_1.fastq', 'HOLT5_RD-P1-134_1.fastq', 'MOAT10_RD-P1-145_1.fastq']\n",
        "Parameter values =[0, 2, 4]\n",
        "#!/bin/bash\n",
        "\n",
        "mkdir GF10_RD-P1-104_1\n",
        "mkdir GF10_RD-P1-104_1/M_tests/\n",
        "mkdir GF10_RD-P1-104_1/M_tests/M_0/; ustacks -t fastq -M 0 -m 6 -p 8 -d -r -i 1 -f GF10_RD-P1-104_1.fastq -o GF10_RD-P1-104_1/M_tests/M_0/ ;\n",
        "mkdir GF10_RD-P1-104_1/M_tests/M_2/; ustacks -t fastq -M 2 -m 6 -p 8 -d -r -i 1 -f GF10_RD-P1-104_1.fastq -o GF10_RD-P1-104_1/M_tests/M_2/ ;\n",
        "mkdir GF10_RD-P1-104_1/M_tests/M_4/; ustacks -t fastq -M 4 -m 6 -p 8 -d -r -i 1 -f GF10_RD-P1-104_1.fastq -o GF10_RD-P1-104_1/M_tests/M_4/ ;\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "#!/bin/bash\n",
        "\n",
        "mkdir HOLT5_RD-P1-134_1\n",
        "mkdir HOLT5_RD-P1-134_1/M_tests/\n",
        "mkdir HOLT5_RD-P1-134_1/M_tests/M_0/; ustacks -t fastq -M 0 -m 6 -p 8 -d -r -i 2 -f HOLT5_RD-P1-134_1.fastq -o HOLT5_RD-P1-134_1/M_tests/M_0/ ;\n",
        "mkdir HOLT5_RD-P1-134_1/M_tests/M_2/; ustacks -t fastq -M 2 -m 6 -p 8 -d -r -i 2 -f HOLT5_RD-P1-134_1.fastq -o HOLT5_RD-P1-134_1/M_tests/M_2/ ;\n",
        "mkdir HOLT5_RD-P1-134_1/M_tests/M_4/; ustacks -t fastq -M 4 -m 6 -p 8 -d -r -i 2 -f HOLT5_RD-P1-134_1.fastq -o HOLT5_RD-P1-134_1/M_tests/M_4/ ;\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "#!/bin/bash\n",
        "\n",
        "mkdir MOAT10_RD-P1-145_1\n",
        "mkdir MOAT10_RD-P1-145_1/M_tests/\n",
        "mkdir MOAT10_RD-P1-145_1/M_tests/M_0/; ustacks -t fastq -M 0 -m 6 -p 8 -d -r -i 3 -f MOAT10_RD-P1-145_1.fastq -o MOAT10_RD-P1-145_1/M_tests/M_0/ ;\n",
        "mkdir MOAT10_RD-P1-145_1/M_tests/M_2/; ustacks -t fastq -M 2 -m 6 -p 8 -d -r -i 3 -f MOAT10_RD-P1-145_1.fastq -o MOAT10_RD-P1-145_1/M_tests/M_2/ ;\n",
        "mkdir MOAT10_RD-P1-145_1/M_tests/M_4/; ustacks -t fastq -M 4 -m 6 -p 8 -d -r -i 3 -f MOAT10_RD-P1-145_1.fastq -o MOAT10_RD-P1-145_1/M_tests/M_4/ ;\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "TAG COUNTER\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "MOAT10 [51733, 48780, 47803]\n",
        "TAG COUNTER\n",
        "GF10 [49381, 44470, 43241]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "TAG COUNTER\n",
        "HOLT5 [84324, 72942, 67766]\n",
        "[23, 15, 13, 9, 9, 17, 10, 14, 29, 13]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[17, 23, 12, 13, 23, 20, 15, 21, 24, 30]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[12, 11, 20, 19, 26, 21, 9, 12, 24, 16]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[21, 14, 17, 15, 16, 25, 19, 15, 12, 13]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[13, 21, 15, 17, 12, 15, 13, 17, 10, 25]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[89, 702, 414, 2497, 310, 513, 1133, 302, 485, 97]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[46, 44, 40, 35, 32, 49, 42, 15, 43, 30]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[790, 2699, 507, 1123, 1402, 11117, 2218, 1248, 378, 1427]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[790, 2699, 507, 1123, 1402, 11117, 2218, 1248, 378, 1427]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "number of coverage plots = 9"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "sample names ="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "set(['MOAT10', 'GF10', 'HOLT5'])\n",
        "MOAT10\n",
        "[41.58, 44.34, 45.36]\n",
        "GF10\n",
        "[16.97, 18.91, 19.53]\n",
        "HOLT5"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[18.07, 20.74, 22.26]\n"
       ]
      }
     ],
     "prompt_number": 45
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Make a list of sample names"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}