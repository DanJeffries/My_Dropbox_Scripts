{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "working_dir=\"/media/dan/34D5D1CE642D7E36/2013076_Hanfling_Bernd/Stacks/Stacks_analyses_V3/Pure_crucian_analysis_V2/populations_all_pops_noSD/\"\n",
    "sumstats = open(working_dir+\"batch_1.sumstats.tsv\", 'r').readlines()\n",
    "populations = open(working_dir+\"uniq_pops.txt\", 'r').readlines()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "populations 18\n"
     ]
    }
   ],
   "source": [
    "print \"populations\", len(populations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## make a dictionary of keys being the pop ID and the values being the locus ID of loci with higher than 0.6 Ho\n",
    "black_list = {}\n",
    "for mykey in range(1,len(populations)+1):\n",
    "    black_list[mykey] = []\n",
    "    line_number = 1\n",
    "    for line in sumstats:\n",
    "        if '#' not in line and line.split()[5] == str(mykey) and float(line.split(\"\\t\")[10]) > 0.5:\n",
    "            #print line_number,line.split()[1],mykey, line.split()[5], line.split(\"\\t\")[10]\n",
    "            black_list[mykey].append(line.split()[1])\n",
    "        line_number +=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of blacklisted loci =  2446\n"
     ]
    }
   ],
   "source": [
    "## ok, now for all loci - if the loci is present in lists of more than one pop, then get rid of it!\n",
    "\n",
    "## make lists of uniq locus names (so you dont count loci with more than one SNP twice)\n",
    "\n",
    "def f1(seq):\n",
    "    set = {}\n",
    "    map(set.__setitem__, seq, [])\n",
    "    return set.keys()\n",
    "\n",
    "locus_list = []\n",
    "for i,v in black_list.items():\n",
    "    for loc in f1(v):\n",
    "        locus_list.append(loc)\n",
    "\n",
    "## Count the number of populations a locus comes up in        \n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "locus_counts = Counter(locus_list)\n",
    "#print locus_counts\n",
    "\n",
    "## Write any loci that have Ho of higher than 0.5 in more than 2 populations to a file\n",
    "\n",
    "blacklist_file = open(working_dir+\"blacklist.txt\", 'w')\n",
    "whitelist_file = open(working_dir+\"whitelist.txt\", 'w')\n",
    "\n",
    "loc_count = 0\n",
    "for i,v in locus_counts.items():\n",
    "    if locus_counts[i] > 0:\n",
    "        loc_count += 1\n",
    "        blacklist_file.write(i+\"\\n\")\n",
    "    elif locus_counts[i] == 0:\n",
    "        whitelist_file.write(i+\"\\n\")\n",
    "        \n",
    "\n",
    "blacklist_file.close()\n",
    "whitelist_file.close()\n",
    "print \"Number of blacklisted loci = \", loc_count\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "###Note that the sumstats file contains all snps, where as the vcf contains only one per tag if i use the --write_single_snp flag. So the number of snps removed from the vcf is very likely to be lower than the number in the blacklist!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
