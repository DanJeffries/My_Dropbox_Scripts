{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "workingdir = \"/media/dan/34D5D1CE642D7E36/2013076_Hanfling_Bernd/Stacks/Stacks_analyses_TRIMMED/Thesis_Incremental_runs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CRU_GIB_TESTDIR_3\t0\t123593\t3699\n",
      "CRU_GIB_TESTDIR_3\t1\t111257\t9124\n",
      "CRU_GIB_TESTDIR_3\t2\t103098\t14055\n",
      "CRU_GIB_TESTDIR_3\t3\t97356\t17917\n",
      "CRU_GIB_TESTDIR_3\t4\t93705\t20399\n",
      "CRU_GIB_TESTDIR_3\t5\t91204\t21964\n",
      "CRU_GIB_TESTDIR_3\t6\t89553\t22897\n",
      "CRU_GIB_TESTDIR_3\t7\t88389\t23511\n",
      "CRU_GIB_TESTDIR_3\t8\t87448\t23926\n",
      "CRU_GIB_TESTDIR_3\t9\t86729\t24234\n",
      "CRU_CYP_TESTDIR_1\t0\t105338\t5401\n",
      "CRU_CYP_TESTDIR_1\t1\t101905\t5948\n",
      "CRU_CYP_TESTDIR_1\t2\t100256\t6315\n",
      "CRU_CYP_TESTDIR_1\t3\t99138\t6696\n",
      "CRU_CYP_TESTDIR_1\t4\t98319\t7077\n",
      "CRU_CYP_TESTDIR_1\t5\t97657\t7277\n",
      "CRU_CYP_TESTDIR_1\t6\t97147\t7429\n",
      "CRU_CYP_TESTDIR_1\t7\t96722\t7572\n",
      "CRU_CYP_TESTDIR_1\t8\t96397\t7678\n",
      "CRU_CYP_TESTDIR_1\t9\t96145\t7755\n",
      "CRU_CYP_TESTDIR_2\t0\t107028\t5819\n",
      "CRU_CYP_TESTDIR_2\t1\t102585\t6318\n",
      "CRU_CYP_TESTDIR_2\t2\t100907\t6576\n",
      "CRU_CYP_TESTDIR_2\t3\t99929\t6811\n",
      "CRU_CYP_TESTDIR_2\t4\t99252\t7061\n",
      "CRU_CYP_TESTDIR_2\t5\t98684\t7192\n",
      "CRU_CYP_TESTDIR_2\t6\t98265\t7292\n",
      "CRU_CYP_TESTDIR_2\t7\t97940\t7371\n",
      "CRU_CYP_TESTDIR_2\t8\t97658\t7453\n",
      "CRU_CYP_TESTDIR_2\t9\t97414\t7526\n",
      "CRU_GIB_TESTDIR_1\t0\t124197\t3786\n",
      "CRU_GIB_TESTDIR_1\t1\t111826\t9259\n",
      "CRU_GIB_TESTDIR_1\t2\t103628\t14191\n",
      "CRU_GIB_TESTDIR_1\t3\t98202\t17894\n",
      "CRU_GIB_TESTDIR_1\t4\t94613\t20283\n",
      "CRU_GIB_TESTDIR_1\t5\t92246\t21783\n",
      "CRU_GIB_TESTDIR_1\t6\t90698\t22680\n",
      "CRU_GIB_TESTDIR_1\t7\t89615\t23218\n",
      "CRU_GIB_TESTDIR_1\t8\t88713\t23595\n",
      "CRU_GIB_TESTDIR_1\t9\t87966\t23912\n",
      "CRU_GIB_TESTDIR_2\t0\t118090\t13444\n",
      "CRU_GIB_TESTDIR_2\t1\t107569\t16929\n",
      "CRU_GIB_TESTDIR_2\t2\t101992\t18475\n",
      "CRU_GIB_TESTDIR_2\t3\t98504\t19545\n",
      "CRU_GIB_TESTDIR_2\t4\t96390\t20309\n",
      "CRU_GIB_TESTDIR_2\t5\t93575\t22003\n",
      "CRU_GIB_TESTDIR_2\t6\t91547\t23122\n",
      "CRU_GIB_TESTDIR_2\t7\t90194\t23775\n",
      "CRU_GIB_TESTDIR_2\t8\t89170\t24222\n",
      "CRU_GIB_TESTDIR_2\t9\t88321\t24541\n",
      "CRU_GOLD_TESTDIR_1\t0\t113818\t3611\n",
      "CRU_GOLD_TESTDIR_1\t1\t104015\t8780\n",
      "CRU_GOLD_TESTDIR_1\t2\t96490\t13546\n",
      "CRU_GOLD_TESTDIR_1\t3\t90984\t17274\n",
      "CRU_GOLD_TESTDIR_1\t4\t87328\t19797\n",
      "CRU_GOLD_TESTDIR_1\t5\t84897\t21357\n",
      "CRU_GOLD_TESTDIR_1\t6\t83124\t22347\n",
      "CRU_GOLD_TESTDIR_1\t7\t81916\t22952\n",
      "CRU_GOLD_TESTDIR_1\t8\t81008\t23342\n",
      "CRU_GOLD_TESTDIR_1\t9\t80283\t23668\n",
      "CRU_GOLD_TESTDIR_2\t0\t103210\t13338\n",
      "CRU_GOLD_TESTDIR_2\t1\t96954\t15865\n",
      "CRU_GOLD_TESTDIR_2\t2\t93498\t17159\n",
      "CRU_GOLD_TESTDIR_2\t3\t91395\t17972\n",
      "CRU_GOLD_TESTDIR_2\t4\t90161\t18503\n",
      "CRU_GOLD_TESTDIR_2\t5\t89365\t18783\n",
      "CRU_GOLD_TESTDIR_2\t6\t88769\t18999\n",
      "CRU_GOLD_TESTDIR_2\t7\t88358\t19142\n",
      "CRU_GOLD_TESTDIR_2\t8\t88027\t19222\n",
      "CRU_GOLD_TESTDIR_2\t9\t87698\t19309\n",
      "CRU_GOLD_TESTDIR_3\t0\t114304\t3721\n",
      "CRU_GOLD_TESTDIR_3\t1\t105022\t9022\n",
      "CRU_GOLD_TESTDIR_3\t2\t97865\t13863\n",
      "CRU_GOLD_TESTDIR_3\t3\t92414\t17612\n",
      "CRU_GOLD_TESTDIR_3\t4\t88856\t20086\n",
      "CRU_GOLD_TESTDIR_3\t5\t86415\t21635\n",
      "CRU_GOLD_TESTDIR_3\t6\t84745\t22620\n",
      "CRU_GOLD_TESTDIR_3\t7\t83536\t23220\n",
      "CRU_GOLD_TESTDIR_3\t8\t82620\t23618\n",
      "CRU_GOLD_TESTDIR_3\t9\t81932\t23934\n",
      "CRU_ONLY_TESTDIR_1\t0\t60031\t43221\n",
      "CRU_ONLY_TESTDIR_1\t1\t57626\t44948\n",
      "CRU_ONLY_TESTDIR_1\t2\t56842\t45214\n",
      "CRU_ONLY_TESTDIR_1\t3\t56577\t45277\n",
      "CRU_ONLY_TESTDIR_1\t4\t56420\t45310\n",
      "CRU_ONLY_TESTDIR_1\t5\t56283\t45329\n",
      "CRU_ONLY_TESTDIR_1\t6\t56162\t45344\n",
      "CRU_ONLY_TESTDIR_1\t7\t56058\t45354\n",
      "CRU_ONLY_TESTDIR_1\t8\t55964\t45376\n",
      "CRU_ONLY_TESTDIR_1\t9\t55873\t45389\n",
      "CRU_ONLY_TESTDIR_2\t0\t74404\t36871\n",
      "CRU_ONLY_TESTDIR_2\t1\t66081\t41395\n",
      "CRU_ONLY_TESTDIR_2\t2\t64625\t42055\n",
      "CRU_ONLY_TESTDIR_2\t3\t64059\t42229\n",
      "CRU_ONLY_TESTDIR_2\t4\t63731\t42302\n",
      "CRU_ONLY_TESTDIR_2\t5\t63422\t42352\n",
      "CRU_ONLY_TESTDIR_2\t6\t63186\t42386\n",
      "CRU_ONLY_TESTDIR_2\t7\t62975\t42423\n",
      "CRU_ONLY_TESTDIR_2\t8\t62781\t42451\n",
      "CRU_ONLY_TESTDIR_2\t9\t62585\t42488\n",
      "CRU_ONLY_TESTDIR_3\t0\t163428\t0\n",
      "CRU_ONLY_TESTDIR_3\t1\t75231\t34930\n",
      "CRU_ONLY_TESTDIR_3\t2\t69840\t38175\n",
      "CRU_ONLY_TESTDIR_3\t3\t68214\t38979\n",
      "CRU_ONLY_TESTDIR_3\t4\t67469\t39225\n",
      "CRU_ONLY_TESTDIR_3\t5\t67033\t39321\n",
      "CRU_ONLY_TESTDIR_3\t6\t66709\t39399\n",
      "CRU_ONLY_TESTDIR_3\t7\t66409\t39482\n",
      "CRU_ONLY_TESTDIR_3\t8\t66131\t39549\n",
      "CRU_ONLY_TESTDIR_3\t9\t65888\t39612\n",
      "BOOM!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from collections import Counter\n",
    "\n",
    "def file_len(fname): ## quick and memory cheap way of getting file length\n",
    "    with open(fname) as f:\n",
    "        for i, l in enumerate(f):\n",
    "            pass\n",
    "    return i + 1\n",
    "\n",
    "outputs = open(workingdir+\"/Total_and_shared_catalog_tags.txt\", 'w')\n",
    "header = \"Catalog\\tN\\tTotal_tags\\tShared_tags\\n\"\n",
    "outputs.write(header)\n",
    "\n",
    "for root, dirs, files in os.walk(workingdir):\n",
    "    for fil in files:\n",
    "        if \"TESTDIR\" in root and \"IncreMental_C\" in root and \"n_tests\" in root and \"n_\" in root and \"tags\" in fil:\n",
    "            tags_file = \"%s/%s\" %(root, fil)\n",
    "            catalog_spp = tags_file.split(\"/\")[8]\n",
    "            N = tags_file.split(\"/\")[11].split(\"_\")[1]\n",
    "            N_total_tags = file_len(tags_file)\n",
    "            \n",
    "            sample_dict = {}\n",
    "            for line in open(tags_file, 'r').readlines():\n",
    "                sample_field = line.split()[7]\n",
    "                #print \"sample field\", sample_field\n",
    "                tag_ID = line.split()[2]\n",
    "                sample_IDs = []\n",
    "                for sample in sample_field.split(\",\"): ## get sample IDs in line\n",
    "                    sample_ID = str(sample.split(\"_\")[0])\n",
    "                    if sample_ID not in sample_IDs:\n",
    "                        sample_IDs.append(sample_ID)\n",
    "                for sample_ID in sample_IDs: # add the tag number to the samples dict slot\n",
    "                    if sample_ID not in sample_dict:\n",
    "                        sample_dict[sample_ID] = []\n",
    "                        sample_dict[sample_ID].append(tag_ID)\n",
    "                    else:\n",
    "                        sample_dict[sample_ID].append(tag_ID)\n",
    "\n",
    "\n",
    "                \n",
    "            sample_dict[sample_ID].append(tag_ID)\n",
    "            \n",
    "            ## now flatted dict into lists, count the occurance of each tag, if a tag has a count of 3 then it is shared by all 3 samples\n",
    "            \n",
    "            flat_list = [item for sublist in sample_dict.values() for item in sublist]\n",
    "            counted_tags = Counter(flat_list)\n",
    "            \n",
    "            ## Now count the number of tags shared in all 3 samples\n",
    "            shared_tags = []\n",
    "            for tag, count in counted_tags.items():\n",
    "                if count == 3:\n",
    "                    shared_tags.append(tag)\n",
    "            #print \"number of shared tags=\", len(shared_tags)\n",
    "                \n",
    "            \n",
    "            out_line = \"%s\\t%s\\t%s\\t%s\\n\" %(catalog_spp, N, N_total_tags, len(shared_tags))\n",
    "            print out_line.strip()\n",
    "            outputs.write(out_line)\n",
    "\n",
    "outputs.close()\n",
    "print \"BOOM!\"\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/dan/34D5D1CE642D7E36/2013076_Hanfling_Bernd/Stacks/Stacks_analyses_TRIMMED/Thesis_Incremental_runs/reference_aligned/CRU_CYP_TESTDIR_1 batch_1.catalog.tags.tsv\n",
      "/media/dan/34D5D1CE642D7E36/2013076_Hanfling_Bernd/Stacks/Stacks_analyses_TRIMMED/Thesis_Incremental_runs/reference_aligned/CRU_CYP_TESTDIR_2 batch_1.catalog.tags.tsv\n",
      "/media/dan/34D5D1CE642D7E36/2013076_Hanfling_Bernd/Stacks/Stacks_analyses_TRIMMED/Thesis_Incremental_runs/reference_aligned/CRU_GIB_TESTDIR_1 batch_1.catalog.tags.tsv\n",
      "/media/dan/34D5D1CE642D7E36/2013076_Hanfling_Bernd/Stacks/Stacks_analyses_TRIMMED/Thesis_Incremental_runs/reference_aligned/CRU_GIB_TESTDIR_3 batch_1.catalog.tags.tsv\n",
      "/media/dan/34D5D1CE642D7E36/2013076_Hanfling_Bernd/Stacks/Stacks_analyses_TRIMMED/Thesis_Incremental_runs/reference_aligned/CRU_GOLD_TESTDIR_1 batch_1.catalog.tags.tsv\n",
      "/media/dan/34D5D1CE642D7E36/2013076_Hanfling_Bernd/Stacks/Stacks_analyses_TRIMMED/Thesis_Incremental_runs/reference_aligned/CRU_GOLD_TESTDIR_2 batch_1.catalog.tags.tsv\n",
      "/media/dan/34D5D1CE642D7E36/2013076_Hanfling_Bernd/Stacks/Stacks_analyses_TRIMMED/Thesis_Incremental_runs/reference_aligned/CRU_GOLD_TESTDIR_3 batch_1.catalog.tags.tsv\n",
      "/media/dan/34D5D1CE642D7E36/2013076_Hanfling_Bernd/Stacks/Stacks_analyses_TRIMMED/Thesis_Incremental_runs/reference_aligned/CRU_ONLY_TESTDIR_1 batch_1.catalog.tags.tsv\n",
      "/media/dan/34D5D1CE642D7E36/2013076_Hanfling_Bernd/Stacks/Stacks_analyses_TRIMMED/Thesis_Incremental_runs/reference_aligned/CRU_ONLY_TESTDIR_2 batch_1.catalog.tags.tsv.gz\n",
      "/media/dan/34D5D1CE642D7E36/2013076_Hanfling_Bernd/Stacks/Stacks_analyses_TRIMMED/Thesis_Incremental_runs/reference_aligned/CRU_ONLY_TESTDIR_3 batch_1.catalog.tags.tsv.gz\n"
     ]
    }
   ],
   "source": [
    "for root, dirs, files in os.walk(workingdir):\n",
    "    for fil in files:\n",
    "        if \"reference\" in root and \"batch_1.catalog.tags.tsv\" in fil:\n",
    "            print root, fil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for root, dirs, files in os.walk(workingdir):\n",
    "    for fil in files:\n",
    "        if \"reference\" in root and \"batch_1.catalog.tags.tsv\" in fil:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ref aligned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "workingdir = \"/media/dan/34D5D1CE642D7E36/2013076_Hanfling_Bernd/Stacks/Stacks_analyses_TRIMMED/Thesis_Incremental_runs/reference_aligned/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CRU_CYP_TESTDIR_1\t40443\t7739\n",
      "CRU_CYP_TESTDIR_2\t40368\t8443\n",
      "CRU_GIB_TESTDIR_1\t17781\t5664\n",
      "CRU_GIB_TESTDIR_2\t16274\t8089\n",
      "CRU_GIB_TESTDIR_3\t18978\t6305\n",
      "CRU_GOLD_TESTDIR_1\t18610\t5968\n",
      "CRU_GOLD_TESTDIR_2\t17020\t8071\n",
      "CRU_GOLD_TESTDIR_3\t18897\t2158\n",
      "CRU_ONLY_TESTDIR_1\t12618\t11097\n",
      "CRU_ONLY_TESTDIR_2\t13317\t11241\n",
      "CRU_ONLY_TESTDIR_3\t13716\t10905\n",
      "BOOM!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from collections import Counter\n",
    "\n",
    "def file_len(fname): ## quick and memory cheap way of getting file length\n",
    "    with open(fname) as f:\n",
    "        for i, l in enumerate(f):\n",
    "            pass\n",
    "    return i + 1\n",
    "\n",
    "outputs = open(workingdir+\"/Total_and_shared_catalog_tags.txt\", 'w')\n",
    "header = \"Catalog\\tTotal_tags\\tShared_tags\\n\"\n",
    "outputs.write(header)\n",
    "\n",
    "for root, dirs, files in os.walk(workingdir):\n",
    "    for fil in files:\n",
    "        if \"reference\" in root and \"batch_1.catalog.tags.tsv\" in fil:\n",
    "            tags_file = \"%s/%s\" %(root, fil)\n",
    "            catalog_spp = tags_file.split(\"/\")[9]\n",
    "            N_total_tags = file_len(tags_file)\n",
    "            \n",
    "            sample_dict = {}\n",
    "            for line in open(tags_file, 'r').readlines():\n",
    "                sample_field = line.split()[8]\n",
    "                #print \"sample field\", sample_field\n",
    "                tag_ID = line.split()[2]\n",
    "                sample_IDs = []\n",
    "                for sample in sample_field.split(\",\"): ## get sample IDs in line\n",
    "                    sample_ID = str(sample.split(\"_\")[0])\n",
    "                    if sample_ID not in sample_IDs:\n",
    "                        sample_IDs.append(sample_ID)\n",
    "                for sample_ID in sample_IDs: # add the tag number to the samples dict slot\n",
    "                    if sample_ID not in sample_dict:\n",
    "                        sample_dict[sample_ID] = []\n",
    "                        sample_dict[sample_ID].append(tag_ID)\n",
    "                    else:\n",
    "                        sample_dict[sample_ID].append(tag_ID)\n",
    "\n",
    "\n",
    "                \n",
    "            sample_dict[sample_ID].append(tag_ID)\n",
    "            \n",
    "            ## now flatted dict into lists, count the occurance of each tag, if a tag has a count of 3 then it is shared by all 3 samples\n",
    "            \n",
    "            flat_list = [item for sublist in sample_dict.values() for item in sublist]\n",
    "            counted_tags = Counter(flat_list)\n",
    "            \n",
    "            ## Now count the number of tags shared in all 3 samples\n",
    "            shared_tags = []\n",
    "            for tag, count in counted_tags.items():\n",
    "                if count == 3:\n",
    "                    shared_tags.append(tag)\n",
    "            #print \"number of shared tags=\", len(shared_tags)\n",
    "                \n",
    "            \n",
    "            out_line = \"%s\\t%s\\t%s\\n\" %(catalog_spp, N_total_tags, len(shared_tags))\n",
    "            print out_line.strip()\n",
    "            outputs.write(out_line)\n",
    "\n",
    "outputs.close()\n",
    "print \"BOOM!\"\n",
    "          "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
