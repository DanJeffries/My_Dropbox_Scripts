{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define helper functions\n",
    "### Biopython style `UstacksCommandLine` class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import collections\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pylab as py\n",
    "import os\n",
    "import csv\n",
    "from collections import Counter\n",
    "import re\n",
    "import subprocess\n",
    "from Bio.Application import _Option, AbstractCommandline, _Switch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class UstacksCommandLine(AbstractCommandline):\n",
    "    def __init__(self, cmd=\"ustacks\", **kwargs):\n",
    "        \"\"\"\n",
    "        # Any ustacks option and switch\n",
    "        >>> cline_args = {'t': 'fastq',\n",
    "        ...               'f': '../../dan_data/OBY01_1.fil.fq_1',\n",
    "        ...               'o': '../../dan_data/OBY01_1.fi/M_tests/M_1',\n",
    "        ...               'i': 1,\n",
    "        ...               'm': 6,\n",
    "        ...               'M': 1,\n",
    "        ...               'p': 3,\n",
    "        ...               'r': True,\n",
    "        ...               'd': True}\n",
    "        \n",
    "        # This creates a command line object\n",
    "        >>> ustacks_cline = UstacksCommandLine(**cline_args)\n",
    "        \n",
    "        # This prints a string representation\n",
    "        >>> print ustacks_cline\n",
    "        ustacks -t fastq -f ../../dan_data/OBY01_1.fil.fq_1 -o ../../dan_data/OBY01_1.fi/M_tests/M_1 -i 1 -m 6 -M 1 -p 3 -r -d\n",
    "        \n",
    "        # This runs ustacks\n",
    "        >>> stdout, stderr = ustacks_cline()\n",
    "        \n",
    "        # This prints the first line in the allele files of the example reuslts\n",
    "        >>> with open('../../dan_data/OBY01_1.fi/M_tests/M_1/OBY01_1.fil.alleles.tsv') as alleles:\n",
    "        ...     print alleles.readlines()[1].rstrip().split()\n",
    "        ['0', '1', '1', 'C', '78.04', '167']\n",
    "        \"\"\"\n",
    "        \n",
    "        self.parameters = [\n",
    "            _Option([\"-t\", \"t\"],\n",
    "                    \"input file Type. Supported types: fasta, fastq, gzfasta, or gzfastq\",\n",
    "                    is_required=True,\n",
    "                    checker_function=lambda value : value in [\"fasta\", \n",
    "                                                              \"fastq\",\n",
    "                                                              \"gzfasta\",\n",
    "                                                              \"gzfastq\"],\n",
    "                    equate=False),\n",
    "            _Option([\"-f\", \"f\"],\n",
    "                    \"input file path\",\n",
    "                    is_required=True,\n",
    "                    filename=True,\n",
    "                    equate=False),\n",
    "            _Option([\"-o\", \"o\"],\n",
    "                    \"output path to write results\",\n",
    "                    is_required=False,\n",
    "                    filename=True,\n",
    "                    equate=False),\n",
    "            _Option([\"-i\", \"i\"],\n",
    "                    \"SQL ID to insert into the output to identify this sample\",\n",
    "                    is_required=False,\n",
    "                    equate=False),\n",
    "            _Option([\"-m\", \"m\"],\n",
    "                    \"Minimum depth of coverage required to create a stack (default 3)\",\n",
    "                    is_required=False,\n",
    "                    checker_function=lambda value : isinstance(value,int),\n",
    "                    equate=False),\n",
    "            _Option([\"-M\", \"M\"],\n",
    "                    \"Maximum distance (in nucleotides) allowed between stacks (default 2)\",\n",
    "                    is_required=False,\n",
    "                    checker_function=lambda value : isinstance(value,int),\n",
    "                    equate=False),\n",
    "            _Option([\"-N\", \"N\"],\n",
    "                    \"Maximum distance allowed to align secondary reads to primary stacks (default: M + 2)\",\n",
    "                    is_required=False,\n",
    "                    checker_function=lambda value : isinstance(value,int),\n",
    "                    equate=False),\n",
    "            _Switch([\"-R\", \"R\"],\n",
    "                    \"retain unused reads\"), \n",
    "            _Switch([\"-H\", \"H\"],\n",
    "                    \"disable calling haplotypes from secondary reads\"),\n",
    "            _Option([\"-p\", \"p\"],\n",
    "                    \"enable parallel execution with num_threads threads\",\n",
    "                    is_required=False,\n",
    "                    checker_function=lambda value : isinstance(value,int),\n",
    "                    equate=False),  \n",
    "            _Switch([\"-h\", \"h\"],\n",
    "                    \"display this help messsage\"),\n",
    "            \n",
    "            # Stack assembly options:\n",
    "            _Switch([\"-r\", \"r\"],\n",
    "                    \"enable the Removal algorithm, to drop highly-repetitive stacks (and nearby errors) from the algorithm\"), \n",
    "            _Switch([\"-d\", \"d\"],\n",
    "                    \"enable the Deleveraging algorithm, used for resolving over merged tags\"),\n",
    "            _Option([\"--max_locus_stacks\", \"-max_locus_stacks\",\"max_locus_stacks\"],\n",
    "                    \"maximum number of stacks at a single de novo locus (default 3)\",\n",
    "                    is_required=False,\n",
    "                    checker_function=lambda value : isinstance(value,int),\n",
    "                    equate=False),\n",
    "            \n",
    "            # Model options:\n",
    "            _Option([\"--model_type\", \"-model_type\",\"model_type\"],\n",
    "                    \"either 'snp' (default), 'bounded', or 'fixed'\",\n",
    "                    is_required=False,\n",
    "                    checker_function=lambda value : value in [\"snp\", \n",
    "                                                              \"bounded\",\n",
    "                                                              \"fixed\"],\n",
    "                    equate=False),\n",
    "            \n",
    "            # For the SNP or Bounded SNP model: \n",
    "            _Option([\"--alpha\", \"-alpha\",\"alpha\"],\n",
    "                    \"chi square significance level required to call a heterozygote or homozygote, either 0.1, 0.05 (default), 0.01, or 0.001\",\n",
    "                    is_required=False,\n",
    "                    checker_function=lambda value : value in [0.1, \n",
    "                                                              0.05,\n",
    "                                                              0.01,\n",
    "                                                              0.001],\n",
    "                    equate=False),\n",
    "            \n",
    "            \n",
    "            # For the Bounded SNP model:\n",
    "            _Option([\"--bound_low\", \"-bound_low\",\"bound_low\"],\n",
    "                    \"lower bound for epsilon, the error rate, between 0 and 1.0 (default 0)\",\n",
    "                    is_required=False,\n",
    "                    checker_function=lambda value : 0 <= value <= 1,\n",
    "                    equate=False),\n",
    "            _Option([\"--bound_high\", \"-bound_high\",\"bound_high\"],\n",
    "                    \"upper bound for epsilon, the error rate, between 0 and 1.0 (default 1)\",\n",
    "                    is_required=False,\n",
    "                    checker_function=lambda value : 0 <= value <= 1,\n",
    "                    equate=False),\n",
    "            \n",
    "            # For the Fixed model:\n",
    "            _Option([\"--bc_err_freq\", \"-bc_err_freq\",\"bc_err_freq\"],\n",
    "                    \"specify the barcode error frequency, between 0 and 1.0\",\n",
    "                    is_required=False,\n",
    "                    checker_function=lambda value : 0 <= value <= 1,\n",
    "                    equate=False)\n",
    "                           ]\n",
    "        AbstractCommandline.__init__(self, cmd, **kwargs) \n",
    "\n",
    "## With this uncommented, the examples in the \n",
    "## docstring will be run and the outputs compared\n",
    "#if __name__ == \"__main__\":\n",
    "#    import doctest\n",
    "#    doctest.testmod()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the incrementation and helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## this function takes the string to be searched and a dictionary of replacements\n",
    "def replace_all(text,dic): \n",
    "    for i, j in dic.iteritems(): \n",
    "        text = text.replace(i,j) ## for each dictionary entry, replace the \"key\" with the \"value\" in the text\n",
    "    return text\n",
    "\n",
    "\n",
    "## Define a cool little helper function for \"natural sorting\". (no idea how it works though!)\n",
    "def natural_key(string_): \n",
    "    return [int(s) if s.isdigit() else s for s in re.split(r'(\\d+)', string_)]\n",
    "\n",
    "\n",
    "## This function makes the command line object and then runs it. \n",
    "\n",
    "def make_and_run_command_lines(param, param_values, parent_dir_path, sample, file_format, threads, ID):\n",
    "    \n",
    "    # fixed values\n",
    "    default = {'M': 3, \n",
    "               'm': 6}\n",
    "              # MS as stacks default (doesn't need to be specified in command line)\n",
    "    \n",
    "    batch_params = {}\n",
    "    \n",
    "    for val in param_values:\n",
    "        \n",
    "        # make necassary directories\n",
    "        dirname = '%s%s/%s_tests/%s_%i'%(parent_dir_path,str(sample.partition(\".\")[0]),param,param,val)\n",
    "        if not os.path.exists(dirname):\n",
    "            try:\n",
    "                os.makedirs(dirname)\n",
    "            except:\n",
    "                os.mkdir(dirname)\n",
    "            \n",
    "            \n",
    "        # make command line\n",
    "        args = {}\n",
    "        args['t'] = file_format\n",
    "        args['p'] = threads\n",
    "        args['d'] = True\n",
    "        args['r'] = True\n",
    "        args['i'] = str(ID)\n",
    "        args['f'] = \"%s%s\"%(parent_dir_path,str(sample))\n",
    "        args['o'] = dirname\n",
    "        \n",
    "        if param == 'MS':\n",
    "            args['max_locus_stacks'] = val\n",
    "            args.update(default)\n",
    "        else:\n",
    "            args[param] = val\n",
    "            for key in default:\n",
    "                if not key == param:\n",
    "                    args[key] = default[key]\n",
    "                    \n",
    "        cline = UstacksCommandLine(**args)\n",
    "        print str(cline)\n",
    "        stderr, stdout = cline()\n",
    "        batch_params[\"%s_%i\"%(args['i'], val)] = args\n",
    "        \n",
    "        \n",
    "    return batch_params          \n",
    "                            \n",
    "        \n",
    "             \n",
    "\n",
    "\n",
    "def IncreMental_U(param, start_value, stop_value, increment, parent_dir_path, file_format, threads):\n",
    "## parent_dir_path - the path to look for raw read .fastq files must have the trailing '/' in it.\n",
    "    \n",
    "    \n",
    "    stop_value = stop_value+1\n",
    "    \n",
    "    ##lists and command templates \n",
    "    sample_names = [] \n",
    "    param_values = range(start_value, stop_value, increment)\n",
    "    \n",
    "    ## Define subfunctions ---------------------------------------------------------\n",
    "            \n",
    "    ## TAG COUNTER ##         \n",
    "    def Tag_counter(directory, parameter):\n",
    "        c = Counter()\n",
    "        sample_names = []\n",
    "        tag_data = []\n",
    "        names = []\n",
    "    \n",
    "    \n",
    "        ## Function to count the length of a file\n",
    "    \n",
    "        def file_len(data):\n",
    "                for i, l in enumerate(data):\n",
    "                    pass\n",
    "                return i + 1\n",
    "    \n",
    "\n",
    "        ## get file names and paths\n",
    "        if parameter == 'm':\n",
    "            for root, dirs, files in os.walk(parent_dir_path):\n",
    "                for fil in files:\n",
    "                    if fil.endswith(\"tags.tsv\") and 'catalog' not in fil and root.split('/')[11].startswith('m'):\n",
    "                        print fil\n",
    "                        data_file = open(str(root+'/'+fil), 'r') ## looking in tags files for all the tests for this parameter\n",
    "                        tag_tally = 0\n",
    "                        for line in data_file.readlines():\n",
    "                            if 'consensus' in line:\n",
    "                                tag_tally +=1\n",
    "                        tag_data.append(str(root.split('/')[-1])+'/'+str(fil)+\"\\t\"+str(tag_tally)) ## put tag counts into a list with sample name\n",
    "                        print \"Tags counted\"\n",
    "                        \n",
    "            tag_data = sorted(tag_data, key = natural_key) ## Sort and write this to a list in the parent directory\n",
    "            f = open(directory + \"m_tests_Tag_numbers.txt\", 'w')\n",
    "            for i in tag_data:\n",
    "                print i\n",
    "                f.write(i+\"\\n\")\n",
    "            f.close()\n",
    "\n",
    "    \n",
    "            ## get the sample names\n",
    "            for i in tag_data:\n",
    "                names.append(i.split('\\t')[0].split('/')[-1])\n",
    "            names = set(names)\n",
    "            print names    \n",
    "            \n",
    "            ##plot the figures\n",
    "            fig = plt.figure()\n",
    "            plt.subplots_adjust(hspace = 0.5) ## adjust subplots\n",
    "            plot_number =1\n",
    "            for i in names:\n",
    "                tag_numbers = []\n",
    "                for item in tag_data:\n",
    "                    if i in item:\n",
    "                        tag_numbers.append(int(item.split('\\t')[1]))\n",
    "                print \"TAG COUNTER\\n\", i, tag_numbers, \"stop_value = \", stop_value\n",
    "                fig.add_subplot(np.round((len(names)/2)+1),2,plot_number)\n",
    "                plt.scatter(range(start_value, stop_value, increment),tag_numbers) ## Manually input the same parameter range used in incremental IncreMental here for the x axis labels.\n",
    "                plt.plot(range(start_value, stop_value, increment),tag_numbers)\n",
    "                plt.title(i+\" Change in number of tags with m incrementation\", fontsize = 5)\n",
    "                plt.xlabel(\"Ustacks m Value\", fontsize = 10)\n",
    "                plt.ylabel(\"Number of tags\", fontsize = 10)\n",
    "                plt.xticks(fontsize = 7)\n",
    "                plt.yticks(fontsize = 7)\n",
    "        \n",
    "                tag_numbers = []\n",
    "                plot_number+=1\n",
    "            plt.savefig(directory + \"m_tests_Tags_per_sample.pdf\")\n",
    "            plt.close('all')  \n",
    "            \n",
    "        elif parameter == 'M':\n",
    "            for root, dirs, files in os.walk(parent_dir_path):\n",
    "                for fil in files:\n",
    "                    if fil.endswith(\"tags.tsv\") and 'catalog' not in fil and root.split('/')[-1].startswith('M'):\n",
    "                        print fil\n",
    "                        data_file = open(str(root+'/'+fil), 'r') ## looking in tags files for all the tests for this parameter\n",
    "                        tag_tally = 0\n",
    "                        for line in data_file.readlines():\n",
    "                            if 'consensus' in line: ## count the number of tag consensus lines in the file.\n",
    "                                tag_tally +=1\n",
    "                        tag_data.append(str(root.split('/')[-1])+'/'+str(fil)+\"\\t\"+str(tag_tally)) ## put tag counts into a list with sample name\n",
    "                        print \"Tags counted\"\n",
    "                        \n",
    "            tag_data = sorted(tag_data, key = natural_key) ## Sort and write this to a list in the parent directory\n",
    "            f = open(directory + \"M_tests_Tag_numbers.txt\", 'w')\n",
    "            for i in tag_data:\n",
    "                print i\n",
    "                f.write(i+\"\\n\")\n",
    "            f.close()\n",
    "\n",
    "    \n",
    "            ## get the sample names\n",
    "            for i in tag_data:\n",
    "                names.append(i.split('\\t')[0].split('/')[-1])\n",
    "            names = set(names)\n",
    "            print names    \n",
    "            ##plot the figures\n",
    "            fig = plt.figure()\n",
    "            plt.subplots_adjust(hspace = 0.5) ## adjust subplots\n",
    "            plot_number =1\n",
    "            for i in names:\n",
    "                tag_numbers = []\n",
    "                for item in tag_data:\n",
    "                    if i in item:\n",
    "                        tag_numbers.append(int(item.split('\\t')[1]))\n",
    "                print \"TAG COUNTER\\n\", i, tag_numbers\n",
    "                fig.add_subplot(np.round((len(names)/2)+1),2,plot_number)\n",
    "                plt.scatter(range(start_value, stop_value, increment),tag_numbers) ## Manually input the same parameter range used in incremental IncreMental here for the x axis labels.\n",
    "                plt.plot(range(start_value, stop_value, increment),tag_numbers)\n",
    "                plt.title(i+\" Change in number of tags with M incrementation\", fontsize = 5)\n",
    "                plt.xlabel(\"Ustacks m Value\", fontsize = 10)\n",
    "                plt.ylabel(\"Number of tags\", fontsize = 10)\n",
    "                plt.xticks(fontsize = 7)\n",
    "                plt.yticks(fontsize = 7)\n",
    "        \n",
    "                tag_numbers = []\n",
    "                plot_number+=1\n",
    "            plt.savefig(directory + \"M_tests_Tags_per_sample.pdf\")\n",
    "            plt.close('all')\n",
    "            \n",
    "        ## Max-stacks-per-locus ###\n",
    "        \n",
    "        elif parameter == \"MS\":\n",
    "            for root, dirs, files in os.walk(parent_dir_path):\n",
    "                for fil in files:\n",
    "                    if fil.endswith(\"tags.tsv\") and 'catalog' not in fil and root.split('/')[-1].startswith('MS'):\n",
    "                        print fil\n",
    "                        data_file = open(str(root+'/'+fil), 'r') ## looking in tags files for all the tests for this parameter\n",
    "                        tag_tally = 0\n",
    "                        for line in data_file.readlines():\n",
    "                            if 'consensus' in line:\n",
    "                                tag_tally +=1\n",
    "                        tag_data.append(str(root.split('/')[-1])+'/'+str(fil)+\"\\t\"+str(tag_tally)) ## works nicely just put this into a list with sample name and its nearly done\n",
    "                        print \"Tags counted\"\n",
    "            tag_data = sorted(tag_data, key = natural_key)\n",
    "            f = open(directory + \"MS_tests_Tag_numbers.txt\", 'w')\n",
    "            for i in tag_data:\n",
    "                print i\n",
    "                f.write(i+\"\\n\")\n",
    "            f.close()\n",
    "            \n",
    "        ## get the sample names\n",
    "            for i in tag_data:\n",
    "                names.append(i.split('\\t')[0].split('/')[-1])\n",
    "            names = set(names)\n",
    "            print names    \n",
    "            \n",
    "        ##plot the figures\n",
    "            \n",
    "            fig = plt.figure()\n",
    "            plt.subplots_adjust(hspace = 0.5) ## adjust subplots\n",
    "            plot_number =1\n",
    "            for i in names:\n",
    "                tag_numbers = []\n",
    "                for item in tag_data:\n",
    "                    if i in item:\n",
    "                        tag_numbers.append(int(item.split('\\t')[1]))\n",
    "                print \"TAG COUNTER\\n\", i, tag_numbers\n",
    "                fig.add_subplot(np.round((len(names)/2)+1),2,plot_number)\n",
    "                plt.scatter(range(start_value, stop_value, increment),tag_numbers) ## Manually input the same parameter range used in incremental IncreMental here for the x axis labels.\n",
    "                plt.plot(range(start_value, stop_value, increment),tag_numbers)\n",
    "                plt.title(i+\" Change in number of tags with Max_locus_stacks incrementation\", fontsize = 5)\n",
    "                plt.xlabel(\"Ustacks M_L_S Value\", fontsize = 10)\n",
    "                plt.ylabel(\"Number of tags\", fontsize = 10)\n",
    "                plt.xticks(fontsize = 7)\n",
    "                plt.yticks(fontsize = 7)\n",
    "        \n",
    "                tag_numbers = []\n",
    "                plot_number+=1\n",
    "            plt.savefig(directory + \"MS_tests_Tags_per_sample.pdf\")\n",
    "            plt.close('all')\n",
    "        \n",
    "    \n",
    "    \n",
    "    ## COVERAGE COUNTER ##\n",
    "    \n",
    "    def coverage_counter(file_name):\n",
    "        csvcol3 = []\n",
    "        csvfile = open(file_name, 'rb')\n",
    "        csvread = csv.reader(csvfile, delimiter =\"\\t\") ## read csv in\n",
    "    \n",
    "        for line in csvread:\n",
    "            # outputs in new version of stacks start with a comment \n",
    "            if not line[0].startswith('#'):\n",
    "                csvcol3.append(int(line[2])) ## add the 3 column of each line to a list\n",
    "        csvcol3 = [str(i) for i in csvcol3] ## convert this list of integers to strings\n",
    "    \n",
    "        coverage_count = collections.Counter()\n",
    "        for tagID in csvcol3:\n",
    "            coverage_count[tagID] += 1 ## count the number of times each tag ID occurs (i.e. the coverage)\n",
    "    \n",
    "        coverage_values = []\n",
    "        f = open(str(file_name[:-9]+\" Coverage data.txt\"), 'a') ## make a new txt file for coverage data\n",
    "    \n",
    "        for i,j in coverage_count.iteritems():\n",
    "            if len(str(j)) > 0:\n",
    "                coverage_values.append(j) ## append the coverage to a list\n",
    "                f.write(str(j) + '\\n') ## write the coverage data to the txt file\n",
    "    \n",
    "        plt.hist(coverage_values, bins = max(coverage_values),range = [0, 100])\n",
    "        plt.hist(coverage_values, bins = max(coverage_values),range = [0, 100])\n",
    "        plt.title(file_name[2:8]+file_name[27:33])\n",
    "        plt.xlabel(\"Coverage\")\n",
    "        plt.ylabel(\"Frequency\")\n",
    "        plt.text(60, 1200, \"Mean tag coverage =\"+ str(np.round(np.mean(coverage_values),2)))\n",
    "        plt.savefig(file_name.rpartition('/')[0]+\"/Coverage.pdf\")\n",
    "        plt.close()\n",
    "    \n",
    "        f.close()\n",
    "        print coverage_values[:10]\n",
    "        \n",
    "        ## COVERAGE COUNTER LOOPER ## \n",
    "        \n",
    "    def coverage_counter_looper(directory, parameter): ## make sure this is the right parent directory - i.e. contains the sample name folder created by increMental\n",
    "        tsvs = []\n",
    "        subdirs = []\n",
    "        cov_files = []\n",
    "        \n",
    "        ### BIG if statement - if the parameter is M or m\n",
    "    \n",
    "        if parameter == 'M':\n",
    "        \n",
    "        ## Make a list of the files, including their paths from the current directory\n",
    "        \n",
    "            for root, dirs, files in os.walk(str(directory)):\n",
    "                for fil in files:\n",
    "                    if fil.endswith(\".tags.tsv\") and 'catalog' not in fil and 'M_' in root:\n",
    "                        tsvs.append(str(str(root)+'/'+str(fil)))\n",
    "                        subdirs.append(str(str(root)+'/'+str(dirs)))\n",
    "                        print root, fil\n",
    "    \n",
    "            ## Execute coverage counter for all these files\n",
    "    \n",
    "            for tsv in tsvs:\n",
    "                coverage_counter(tsv)           \n",
    "    \n",
    "            ## make the multiplot\n",
    "            ## first get the coverage counter output files\n",
    "    \n",
    "            for root, dirs, files in os.walk(str(directory)):\n",
    "                for fil in files:\n",
    "                    if fil.endswith(\"data.txt\") and 'catalog' not in fil and 'M_' in root:  ## have changed this so hopefully it doesn't pick up increMental_C outputs\n",
    "                        cov_files.append(str(str(root)+'/'+str(fil)))\n",
    "            cov_files = sorted(cov_files, key = natural_key)\n",
    "            plot_number = 1\n",
    "\n",
    "            fig = plt.figure()\n",
    "            plt.subplots_adjust(hspace = 0.8)\n",
    "            data = []\n",
    "            for cov_file in cov_files:    \n",
    "                data_file = open(cov_file, 'r')\n",
    "                for i in data_file.readlines():\n",
    "                    if i > 0:\n",
    "                        data.append(int(i))    \n",
    "    \n",
    "                fig.add_subplot(np.round((len(cov_files)/3)+1),3,plot_number)\n",
    "                plt.hist(data, bins = 100,range = [0, 150])\n",
    "                plt.title(cov_file.split('/')[-1].partition('_')[0]+\" \"+ cov_file.split('/')[-2], fontsize = 5)\n",
    "                py.yticks(fontsize = 5)\n",
    "                py.xticks(fontsize = 5)\n",
    "                plt.xlabel(\"Coverage\", fontsize = 5)\n",
    "                plt.ylabel(\"Frequency\", fontsize = 5)\n",
    "                plt.text(60, 1200, \"Mean tag coverage =\"+ str(np.round(float(np.mean(data)),2)), fontsize = 5)\n",
    "    \n",
    "                plot_number += 1\n",
    "\n",
    "            plt.savefig(directory + 'M_tests_coverage_multiplot.pdf')    \n",
    "            plt.close('all')\n",
    "    \n",
    "    \n",
    "            print('number of coverage plots = '+ str(plot_number -1))\n",
    "    \n",
    "            ### Make the change-in average coverage plot\n",
    "    \n",
    "            sample_coverage = []\n",
    "            sample_names = []\n",
    "            cov_data = []\n",
    "            cov_values = []\n",
    "\n",
    "\n",
    "\n",
    "            ## get file names and paths\n",
    "\n",
    "            for root, dirs, files in os.walk(directory):\n",
    "                for fil in files:\n",
    "                    if fil.endswith(\"data.txt\") and 'M_' in root:\n",
    "                        data_file = open(str(root+'/'+fil), 'r')\n",
    "                        data = [int(i.lstrip('0')) for i in data_file.readlines()]\n",
    "                        sample_coverage.append(fil.partition('_')[0] + \"__\" + root.split('/')[3]+\"\\t\"+ str(np.round(np.mean(data),2)))\n",
    "\n",
    "            ## make a list of uniq sample names\n",
    "\n",
    "            for i in sample_coverage:\n",
    "                sample_names.append(i.split('\\t')[0].partition('_')[0])\n",
    "            sample_names = set(sample_names)\n",
    "            print \"sample names =\" \n",
    "            print sample_names\n",
    "\n",
    "            ## Use this list to separate the data according to the sample it comes from\n",
    "            ## And then plot the graphs in one file and save in parent directory\n",
    "    \n",
    "            fig = plt.figure() ## make fig\n",
    "            plt.subplots_adjust(hspace = 0.5) ## adjust subplots\n",
    "            plot_number =1\n",
    "            for name in sample_names: ## for each sample\n",
    "                for line in sample_coverage:\n",
    "                    if name in line:\n",
    "                        cov_data.append(line)\n",
    "                cov_data = sorted(cov_data, key = natural_key) ## sort \"naturally\"\n",
    "                for i in cov_data:\n",
    "                    cov_values.append(float(i.split()[1]))\n",
    "                print name\n",
    "                print cov_values\n",
    "    \n",
    "            ## And now plot the graphs as subplots in a main fig. Put in parent dir.   \n",
    "    \n",
    "                fig.add_subplot(np.round((len(sample_names)/2)+1),2,plot_number)\n",
    "                plt.scatter(range(start_value, stop_value, increment),cov_values) ## Manually input range from IncreMental here!\n",
    "                plt.plot(range(start_value, stop_value, increment),cov_values)\n",
    "                plt.title(name+\" coverage per tag with M incrementation\", fontsize = 10)\n",
    "                plt.xlabel(\"Ustacks Parameter Value\", fontsize = 10)\n",
    "                plt.ylabel(\"Coverage per tag\", fontsize = 10)\n",
    "                plt.xticks(fontsize = 7)\n",
    "                plt.yticks(fontsize = 7)\n",
    "    \n",
    "                cov_data = []\n",
    "                cov_values = []\n",
    "                plot_number+=1\n",
    "            plt.savefig(directory + \"M_tests_mean_coverage_multiplot.pdf\")\n",
    "            plt.close('all')\n",
    "        \n",
    "        elif parameter == 'm':\n",
    "        \n",
    "        ## Make a list of the files, including their paths from the current directory\n",
    "        \n",
    "            for root, dirs, files in os.walk(str(directory)):\n",
    "                for fil in files:\n",
    "                    if fil.endswith(\".tags.tsv\") and 'catalog' not in fil and 'm_' in root:\n",
    "                        tsvs.append(str(str(root)+'/'+str(fil)))\n",
    "                        print root, fil\n",
    "    \n",
    "            ## Execute coverage counter for all these files\n",
    "    \n",
    "            for tsv in tsvs:\n",
    "                coverage_counter(tsv)           \n",
    "    \n",
    "            ## make the multiplot\n",
    "            ## first get the coverage counter output files\n",
    "    \n",
    "            for root, dirs, files in os.walk(str(directory)):\n",
    "                for fil in files:\n",
    "                    if fil.endswith(\"data.txt\") and 'catalog' not in fil and 'm_' in root:  ## have changed this so hopefully it doesn't pick up increMental_C outputs\n",
    "                        cov_files.append(str(str(root)+'/'+str(fil)))\n",
    "            cov_files = sorted(cov_files, key = natural_key)          \n",
    "            plot_number = 1\n",
    "            \n",
    "            fig = plt.figure()\n",
    "            plt.subplots_adjust(hspace = 0.8)\n",
    "\n",
    "            for cov_file in cov_files:    \n",
    "                print cov_file\n",
    "                data_file = open(cov_file, 'r')\n",
    "                data = [int(i) for i in data_file.readlines()]\n",
    "\n",
    "                fig.add_subplot(np.round((len(cov_files)/3)+1),3,plot_number)\n",
    "                plt.hist(data, bins = 100,range = [0, 150])\n",
    "                plt.title(cov_file.split('/')[-1].partition('_')[0]+\" \"+ cov_file.split('/')[-3], fontsize = 5)\n",
    "                py.yticks(fontsize = 5)\n",
    "                py.xticks(fontsize = 5)\n",
    "                plt.xlabel(\"Coverage\", fontsize = 5)\n",
    "                plt.ylabel(\"Frequency\", fontsize = 5)\n",
    "                plt.text(60, 1200, \"Mean tag coverage =\"+ str(np.round(float(np.mean(data)),2)), fontsize = 5)\n",
    "    \n",
    "                plot_number += 1\n",
    "\n",
    "            plt.savefig(directory + 'm_tests_coverage_multiplot.pdf')    \n",
    "            plt.close('all')\n",
    "    \n",
    "    \n",
    "            print('number of coverage plots = '+ str(plot_number -1))\n",
    "    \n",
    "            ### Make the change-in average coverage plot\n",
    "    \n",
    "            sample_coverage = []\n",
    "            sample_names = []\n",
    "            cov_data = []\n",
    "            cov_values = []\n",
    "\n",
    "\n",
    "            ## get file names and paths\n",
    "\n",
    "            for root, dirs, files in os.walk(directory):\n",
    "                for fil in files:\n",
    "                    if fil.endswith(\"data.txt\") and 'm_' in root:\n",
    "                        data_file = open(str(root+'/'+fil), 'r')\n",
    "                        data = [int(i) for i in data_file.readlines()]\n",
    "                        sample_coverage.append(fil.partition('_')[0] + \"__\" + root.split('/')[3]+\"\\t\"+ str(np.round(np.mean(data),2)))\n",
    "\n",
    "            ## make a list of uniq sample names\n",
    "\n",
    "            for i in sample_coverage:\n",
    "                sample_names.append(i.split('\\t')[0].partition('_')[0])\n",
    "            sample_names = set(sample_names)\n",
    "            print \"sample names =\" \n",
    "            print sample_names\n",
    "\n",
    "            ## Use this list to separate the data according to the sample it comes from\n",
    "            ## And then plot the graphs in one file and save in parent directory\n",
    "    \n",
    "            fig = plt.figure() ## make fig\n",
    "            plt.subplots_adjust(hspace = 0.5) ## adjust subplots\n",
    "            plot_number =1\n",
    "            for name in sample_names: ## for each sample\n",
    "                for line in sample_coverage:\n",
    "                    if name in line:\n",
    "                        cov_data.append(line)\n",
    "                cov_data = sorted(cov_data, key = natural_key) ## sort \"naturally\"\n",
    "                for i in cov_data:\n",
    "                    cov_values.append(float(i.split()[1]))\n",
    "                print name\n",
    "                print cov_values\n",
    "    \n",
    "            ## And now plot the graphs as subplots in a main fig. Put in parent dir.   \n",
    "    \n",
    "                fig.add_subplot(np.round((len(sample_names)/2)+1),2,plot_number)\n",
    "                plt.scatter(range(start_value, stop_value, increment),cov_values) ## remember to change back to start_value, stop_value, increment\n",
    "                plt.plot(range(start_value, stop_value, increment),cov_values)\n",
    "                plt.title(name+\" coverage per tag with m incrementation\", fontsize = 10)\n",
    "                plt.xlabel(\"Ustacks Parameter Value\", fontsize = 10)\n",
    "                plt.ylabel(\"Coverage per tag\", fontsize = 10)\n",
    "                plt.xticks(fontsize = 7)\n",
    "                plt.yticks(fontsize = 7)\n",
    "    \n",
    "                cov_data = []\n",
    "                cov_values = []\n",
    "                plot_number+=1\n",
    "            plt.savefig(directory + \"m_tests_mean_coverage_multiplot.pdf\")\n",
    "            plt.close('all')\n",
    "            \n",
    "        elif parameter == \"max_locus_stacks\":\n",
    "            ## Make a list of the files, including their paths from the current directory\n",
    "        \n",
    "            for root, dirs, files in os.walk(str(directory)):\n",
    "                for fil in files:\n",
    "                    if fil.endswith(\".tags.tsv\") and 'catalog' not in fil and 'MS_' in root:\n",
    "                        tsvs.append(str(str(root)+'/'+str(fil)))\n",
    "                        print root, fil\n",
    "    \n",
    "            ## Execute coverage counter for all these files\n",
    "    \n",
    "            for tsv in tsvs:\n",
    "                coverage_counter(tsv)           \n",
    "    \n",
    "            ## make the multiplot\n",
    "            ## first get the coverage counter output files\n",
    "    \n",
    "            for root, dirs, files in os.walk(str(directory)):\n",
    "                for fil in files:\n",
    "                    if fil.endswith(\"data.txt\") and 'catalog' not in fil and 'MS_' in root:  ## have changed this so hopefully it doesn't pick up increMental_C outputs\n",
    "                        cov_files.append(str(str(root)+'/'+str(fil)))\n",
    "            cov_files = sorted(cov_files, key = natural_key)          \n",
    "            plot_number = 1\n",
    "            \n",
    "            fig = plt.figure()\n",
    "            plt.subplots_adjust(hspace = 0.8)\n",
    "\n",
    "            for cov_file in cov_files:    \n",
    "                print cov_file\n",
    "                data_file = open(cov_file, 'r')\n",
    "                data = [int(i) for i in data_file.readlines()]\n",
    "\n",
    "                fig.add_subplot(np.round((len(cov_files)/3)+1),3,plot_number)\n",
    "                plt.hist(data, bins = 100,range = [0, 150])\n",
    "                plt.title(cov_file.split('/')[-1].partition('_')[0]+\" \"+ cov_file.split('/')[-3], fontsize = 5)\n",
    "                py.yticks(fontsize = 5)\n",
    "                py.xticks(fontsize = 5)\n",
    "                plt.xlabel(\"Coverage\", fontsize = 5)\n",
    "                plt.ylabel(\"Frequency\", fontsize = 5)\n",
    "                plt.text(60, 1200, \"Mean tag coverage =\"+ str(np.round(float(np.mean(data)),2)), fontsize = 5)\n",
    "    \n",
    "                plot_number += 1\n",
    "\n",
    "            plt.savefig(directory + 'MS_tests_coverage_multiplot.pdf')    \n",
    "            plt.close('all')\n",
    "    \n",
    "    \n",
    "            print('number of coverage plots = '+ str(plot_number -1))\n",
    "        \n",
    "        ### Make the change-in average coverage plot\n",
    "    \n",
    "            sample_coverage = []\n",
    "            sample_names = []\n",
    "            cov_data = []\n",
    "            cov_values = []\n",
    "\n",
    "\n",
    "            ## get file names and paths\n",
    "\n",
    "            for root, dirs, files in os.walk(directory):\n",
    "                for fil in files:\n",
    "                    if fil.endswith(\"data.txt\") and 'MS_' in root:\n",
    "                        data_file = open(str(root+'/'+fil), 'r')\n",
    "                        data = [int(i) for i in data_file.readlines()]\n",
    "                        sample_coverage.append(fil.partition('_')[0] + \"__\" + root.split('/')[3]+\"\\t\"+ str(np.round(np.mean(data),2)))\n",
    "\n",
    "            ## make a list of uniq sample names\n",
    "\n",
    "            for i in sample_coverage:\n",
    "                sample_names.append(i.split('\\t')[0].partition('_')[0])\n",
    "            sample_names = set(sample_names)\n",
    "            print \"sample names =\" \n",
    "            print sample_names\n",
    "\n",
    "            ## Use this list to separate the data according to the sample it comes from\n",
    "            ## And then plot the graphs in one file and save in parent directory\n",
    "    \n",
    "            fig = plt.figure() ## make fig\n",
    "            plt.subplots_adjust(hspace = 0.5) ## adjust subplots\n",
    "            plot_number =1\n",
    "            for name in sample_names: ## for each sample\n",
    "                for line in sample_coverage:\n",
    "                    if name in line:\n",
    "                        cov_data.append(line)\n",
    "                cov_data = sorted(cov_data, key = natural_key) ## sort \"naturally\"\n",
    "                for i in cov_data:\n",
    "                    cov_values.append(float(i.split()[1]))\n",
    "                print name\n",
    "                print cov_values\n",
    "    \n",
    "            ## And now plot the graphs as subplots in a main fig. Put in parent dir.   \n",
    "    \n",
    "                fig.add_subplot(np.round((len(sample_names)/2)+1),2,plot_number)\n",
    "                plt.scatter(range(start_value, stop_value, increment),cov_values) ## remember to change back to start_value, stop_value, increment\n",
    "                plt.plot(range(start_value, stop_value, increment),cov_values)\n",
    "                plt.title(name+\" coverage per tag with Max_Locus_stacks incrementation\", fontsize = 10)\n",
    "                plt.xlabel(\"Ustacks M_L_S Parameter Value\", fontsize = 10)\n",
    "                plt.ylabel(\"Coverage per tag\", fontsize = 10)\n",
    "                plt.xticks(fontsize = 7)\n",
    "                plt.yticks(fontsize = 7)\n",
    "    \n",
    "                cov_data = []\n",
    "                cov_values = []\n",
    "                plot_number+=1\n",
    "            plt.savefig(directory + \"MS_tests_mean_coverage_multiplot.pdf\")\n",
    "            plt.close('all')\n",
    "   \n",
    "    \n",
    "    ## RUNNING PIPELINE ---------------------------------------------------------------\n",
    "    \n",
    "        \n",
    "#    ID = 1 ## Assign a different ID to each individual with for a given param value\n",
    "#    \n",
    "#    \n",
    "#    ## Get samples\n",
    "#    for i in os.listdir(parent_dir_path):\n",
    "#        if i.endswith(\".fq_1\") or i.endswith(\".fq\") or i.endswith(\"1.fastq\"): \n",
    " #           sample_names.append(i)\n",
    " #   sample_names = sorted(sample_names) ## Important line - as Incremental_C sorts as well and assigns samples to lists on the basis of their IDs they must be sorted the same way here\n",
    " ##   \n",
    " #   print \"samples present\", sample_names\n",
    " #   print (\"Parameter values =\" + str(param_values))\n",
    "#\n",
    "#    \n",
    "#    analysis_settings = {}\n",
    "#   \n",
    "#    for sample in sample_names: ## Run pipeline for each sample ...\n",
    "#        \n",
    "#        analysis_settings[str(ID)] = make_and_run_command_lines(param, param_values, parent_dir_path,\n",
    "#                                                                sample, file_format, threads, ID)\n",
    "#        ID += 1\n",
    "#\n",
    "#    Tag_counter(parent_dir_path, param)\n",
    " ##   coverage_counter_looper(parent_dir_path, param)\n",
    "#    \n",
    "#    \n",
    "#    \n",
    "#    return analysis_settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Tag_counter' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-1207f1a1cfb5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mTag_counter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"/home/djeffrie/Data/Pnig_RAD/Incremental_tests/\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"M\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'Tag_counter' is not defined"
     ]
    }
   ],
   "source": [
    "Tag_counter(\"/home/djeffrie/Data/Pnig_RAD/Incremental_tests/\", \"M\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the pipline here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples present ['Pnig_1.fq', 'Pnig_20.fq', 'Pnig_30.fq']\n",
      "Parameter values =[2, 3, 4]\n",
      "ustacks -t fastq -f /home/djeffrie/Data/Pnig_RAD/Incremental_tests/Pnig_1.fq -o /home/djeffrie/Data/Pnig_RAD/Incremental_tests/Pnig_1/M_tests/M_2 -i 1 -m 6 -M 2 -p 7 -r -d\n",
      "ustacks -t fastq -f /home/djeffrie/Data/Pnig_RAD/Incremental_tests/Pnig_1.fq -o /home/djeffrie/Data/Pnig_RAD/Incremental_tests/Pnig_1/M_tests/M_3 -i 1 -m 6 -M 3 -p 7 -r -d\n",
      "ustacks -t fastq -f /home/djeffrie/Data/Pnig_RAD/Incremental_tests/Pnig_1.fq -o /home/djeffrie/Data/Pnig_RAD/Incremental_tests/Pnig_1/M_tests/M_4 -i 1 -m 6 -M 4 -p 7 -r -d\n",
      "ustacks -t fastq -f /home/djeffrie/Data/Pnig_RAD/Incremental_tests/Pnig_20.fq -o /home/djeffrie/Data/Pnig_RAD/Incremental_tests/Pnig_20/M_tests/M_2 -i 2 -m 6 -M 2 -p 7 -r -d\n",
      "ustacks -t fastq -f /home/djeffrie/Data/Pnig_RAD/Incremental_tests/Pnig_20.fq -o /home/djeffrie/Data/Pnig_RAD/Incremental_tests/Pnig_20/M_tests/M_3 -i 2 -m 6 -M 3 -p 7 -r -d\n",
      "ustacks -t fastq -f /home/djeffrie/Data/Pnig_RAD/Incremental_tests/Pnig_20.fq -o /home/djeffrie/Data/Pnig_RAD/Incremental_tests/Pnig_20/M_tests/M_4 -i 2 -m 6 -M 4 -p 7 -r -d\n",
      "ustacks -t fastq -f /home/djeffrie/Data/Pnig_RAD/Incremental_tests/Pnig_30.fq -o /home/djeffrie/Data/Pnig_RAD/Incremental_tests/Pnig_30/M_tests/M_2 -i 3 -m 6 -M 2 -p 7 -r -d\n",
      "ustacks -t fastq -f /home/djeffrie/Data/Pnig_RAD/Incremental_tests/Pnig_30.fq -o /home/djeffrie/Data/Pnig_RAD/Incremental_tests/Pnig_30/M_tests/M_3 -i 3 -m 6 -M 3 -p 7 -r -d\n",
      "ustacks -t fastq -f /home/djeffrie/Data/Pnig_RAD/Incremental_tests/Pnig_30.fq -o /home/djeffrie/Data/Pnig_RAD/Incremental_tests/Pnig_30/M_tests/M_4 -i 3 -m 6 -M 4 -p 7 -r -d\n",
      "Pnig_1.tags.tsv\n",
      "<open file '/home/djeffrie/Data/Pnig_RAD/Incremental_tests/Pnig_1/M_tests/M_3/Pnig_1.tags.tsv', mode 'r' at 0x7fed897aa030>\n",
      "Pnig_1.tags.tsv\n",
      "<open file '/home/djeffrie/Data/Pnig_RAD/Incremental_tests/Pnig_1/M_tests/M_1/Pnig_1.tags.tsv', mode 'r' at 0x7fed897aadb0>\n",
      "Pnig_1.tags.tsv\n",
      "<open file '/home/djeffrie/Data/Pnig_RAD/Incremental_tests/Pnig_1/M_tests/M_4/Pnig_1.tags.tsv', mode 'r' at 0x7fed897aa030>\n",
      "Pnig_1.tags.tsv\n",
      "<open file '/home/djeffrie/Data/Pnig_RAD/Incremental_tests/Pnig_1/M_tests/M_2/Pnig_1.tags.tsv', mode 'r' at 0x7fed897aadb0>\n",
      "Pnig_30.tags.tsv\n",
      "<open file '/home/djeffrie/Data/Pnig_RAD/Incremental_tests/Pnig_30/M_tests/M_3/Pnig_30.tags.tsv', mode 'r' at 0x7fed897aa030>\n",
      "Pnig_30.tags.tsv\n",
      "<open file '/home/djeffrie/Data/Pnig_RAD/Incremental_tests/Pnig_30/M_tests/M_4/Pnig_30.tags.tsv', mode 'r' at 0x7fed897aadb0>\n",
      "Pnig_30.tags.tsv\n",
      "<open file '/home/djeffrie/Data/Pnig_RAD/Incremental_tests/Pnig_30/M_tests/M_2/Pnig_30.tags.tsv', mode 'r' at 0x7fed897aa030>\n",
      "Pnig_20.tags.tsv\n",
      "<open file '/home/djeffrie/Data/Pnig_RAD/Incremental_tests/Pnig_20/M_tests/M_3/Pnig_20.tags.tsv', mode 'r' at 0x7fed897aadb0>\n",
      "Pnig_20.tags.tsv\n",
      "<open file '/home/djeffrie/Data/Pnig_RAD/Incremental_tests/Pnig_20/M_tests/M_4/Pnig_20.tags.tsv', mode 'r' at 0x7fed897aa030>\n",
      "Pnig_20.tags.tsv\n",
      "<open file '/home/djeffrie/Data/Pnig_RAD/Incremental_tests/Pnig_20/M_tests/M_2/Pnig_20.tags.tsv', mode 'r' at 0x7fed897aadb0>\n",
      "M_1/Pnig_1.tags.tsv\t85453\n",
      "M_2/Pnig_1.tags.tsv\t83346\n",
      "M_2/Pnig_20.tags.tsv\t95675\n",
      "M_2/Pnig_30.tags.tsv\t56681\n",
      "M_3/Pnig_1.tags.tsv\t82619\n",
      "M_3/Pnig_20.tags.tsv\t94660\n",
      "M_3/Pnig_30.tags.tsv\t56276\n",
      "M_4/Pnig_1.tags.tsv\t82200\n",
      "M_4/Pnig_20.tags.tsv\t94208\n",
      "M_4/Pnig_30.tags.tsv\t56042\n",
      "set(['Pnig_20.tags.tsv', 'Pnig_30.tags.tsv', 'Pnig_1.tags.tsv'])\n",
      "TAG COUNTER\n",
      "Pnig_20.tags.tsv [95675, 94660, 94208]\n",
      "TAG COUNTER\n",
      "Pnig_30.tags.tsv [56681, 56276, 56042]\n",
      "TAG COUNTER\n",
      "Pnig_1.tags.tsv [85453, 83346, 82619, 82200]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "x and y must be the same size",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-1cc8fe3e0709>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mparameter\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtest_params\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m## loop over the paramters to test . . .\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0manalysis_settings\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdir\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mIncreMental_U\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparameter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mworking_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'fastq'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m7\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-3-f3708f0d529f>\u001b[0m in \u001b[0;36mIncreMental_U\u001b[1;34m(param, start_value, stop_value, increment, parent_dir_path, file_format, threads)\u001b[0m\n\u001b[0;32m    643\u001b[0m         \u001b[0mID\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    644\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 645\u001b[1;33m     \u001b[0mTag_counter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparent_dir_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    646\u001b[0m     \u001b[0mcoverage_counter_looper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparent_dir_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    647\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-f3708f0d529f>\u001b[0m in \u001b[0;36mTag_counter\u001b[1;34m(directory, parameter)\u001b[0m\n\u001b[0;32m    179\u001b[0m                 \u001b[1;32mprint\u001b[0m \u001b[1;34m\"TAG COUNTER\\n\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtag_numbers\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m                 \u001b[0mfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_subplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mplot_number\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 181\u001b[1;33m                 \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstop_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mincrement\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtag_numbers\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m## Manually input the same parameter range used in incremental IncreMental here for the x axis labels.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    182\u001b[0m                 \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstop_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mincrement\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtag_numbers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m                 \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\" Change in number of tags with M incrementation\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfontsize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/djeffrie/anaconda/lib/python2.7/site-packages/matplotlib/pyplot.pyc\u001b[0m in \u001b[0;36mscatter\u001b[1;34m(x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, hold, **kwargs)\u001b[0m\n\u001b[0;32m   3198\u001b[0m         ret = ax.scatter(x, y, s=s, c=c, marker=marker, cmap=cmap, norm=norm,\n\u001b[0;32m   3199\u001b[0m                          \u001b[0mvmin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvmin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvmax\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvmax\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3200\u001b[1;33m                          linewidths=linewidths, verts=verts, **kwargs)\n\u001b[0m\u001b[0;32m   3201\u001b[0m         \u001b[0mdraw_if_interactive\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3202\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/djeffrie/anaconda/lib/python2.7/site-packages/matplotlib/axes/_axes.pyc\u001b[0m in \u001b[0;36mscatter\u001b[1;34m(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, **kwargs)\u001b[0m\n\u001b[0;32m   3589\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3590\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3591\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"x and y must be the same size\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3592\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3593\u001b[0m         \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# This doesn't have to match x, y in size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: x and y must be the same size"
     ]
    }
   ],
   "source": [
    "## Batch analysis\n",
    "working_dir = \"/home/djeffrie/Data/Pnig_RAD/Incremental_tests/\"\n",
    "\n",
    "test_params = [\"M\", \"m\"]\n",
    "\n",
    "analysis_settings = {}\n",
    "\n",
    "for parameter in test_params: ## loop over the paramters to test . . . \n",
    "                \n",
    "    analysis_settings[dir] = IncreMental_U(parameter, 2, 4, 1, working_dir, 'fastq', 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On the basis of the above results, decide on the Ustacks parameters to use here, and then run cstacks using these for use in Incremental_C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def Final_Ustacks_command(M_value, m_value, parent_dir_path):\n",
    "       \n",
    "## Define execute function ##\n",
    "        \n",
    "    def execute(bash_file):\n",
    "        f = open(str(bash_file), 'r')\n",
    "        script = f.read()\n",
    "        subprocess.call(script, shell=True)\n",
    "        print script\n",
    "    \n",
    "## Get files ##\n",
    "    \n",
    "    sample_names = []\n",
    "    \n",
    "    for i in os.listdir(parent_dir_path):\n",
    "        if i.endswith(\".fq_1\") or i.endswith(\"1.fastq\"): \n",
    "            sample_names.append(i)\n",
    "    \n",
    "    print (\"Parameter values: M =\"+str(M_value)+\" m =\"+str(m_value)+\"\\n\")\n",
    "    \n",
    "## Write file ##\n",
    "\n",
    "    f = open(str(parent_dir_path +\"Final_Ustacks_commands.sh\"), 'w') ## .. make a bash script file in the current ipython directory...\n",
    "    f.write(\"#!/bin/bash\\n\\nmkdir \"+ parent_dir_path + \"Final_Ustacks_outputs/ \\n\") \n",
    "    \n",
    "    Sample_ID = 1\n",
    "    for sample in sample_names: ## so for each sample ...\n",
    "        final_command_list = []\n",
    "        f.write('ustacks -t fastq -M '+str(M_value)+' -m '+str(m_value)+' -p 8 -d -r -i '+str(Sample_ID)+' -f '+ str(parent_dir_path) + str(sample)+' -o '+ str(parent_dir_path) + 'Final_Ustacks_outputs/ \\n')    \n",
    "        Sample_ID += 1\n",
    "        print (sample.split(\"_\")[0]+\" ID = \"+str(Sample_ID))\n",
    "    f.close()\n",
    "    \n",
    "## Execute the scripts\n",
    "    execute(str(parent_dir_path +\"Final_Ustacks_commands.sh\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Final_Ustacks_command(8,8,'/media/dan/34D5D1CE642D7E36/2013076_Hanfling_Bernd/Stacks/Stacks_analyses_V3/Incremental_tests/Batch_2/all_cru/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter values: M =4 m =2\n",
      "\n",
      "OBY01 ID = 2\n",
      "OU01 ID = 3\n",
      "STYV01 ID = 4\n",
      "#!/bin/bash\n",
      "\n",
      "mkdir /media/dan/34D5D1CE642D7E36/2013076_Hanfling_Bernd/Stacks/Stacks_analyses_TRIMMED/Thesis_Incremental_runs//CRU_ONLY_TESTDIR_1/Final_Ustacks_outputs/ \n",
      "ustacks -t fastq -M 4 -m 2 -p 8 -d -r -i 1 -f /media/dan/34D5D1CE642D7E36/2013076_Hanfling_Bernd/Stacks/Stacks_analyses_TRIMMED/Thesis_Incremental_runs//CRU_ONLY_TESTDIR_1/OBY01_1.fil.fq_1 -o /media/dan/34D5D1CE642D7E36/2013076_Hanfling_Bernd/Stacks/Stacks_analyses_TRIMMED/Thesis_Incremental_runs//CRU_ONLY_TESTDIR_1/Final_Ustacks_outputs/ \n",
      "ustacks -t fastq -M 4 -m 2 -p 8 -d -r -i 2 -f /media/dan/34D5D1CE642D7E36/2013076_Hanfling_Bernd/Stacks/Stacks_analyses_TRIMMED/Thesis_Incremental_runs//CRU_ONLY_TESTDIR_1/OU01_1.fil.fq_1 -o /media/dan/34D5D1CE642D7E36/2013076_Hanfling_Bernd/Stacks/Stacks_analyses_TRIMMED/Thesis_Incremental_runs//CRU_ONLY_TESTDIR_1/Final_Ustacks_outputs/ \n",
      "ustacks -t fastq -M 4 -m 2 -p 8 -d -r -i 3 -f /media/dan/34D5D1CE642D7E36/2013076_Hanfling_Bernd/Stacks/Stacks_analyses_TRIMMED/Thesis_Incremental_runs//CRU_ONLY_TESTDIR_1/STYV01_1.fil.fq_1 -o /media/dan/34D5D1CE642D7E36/2013076_Hanfling_Bernd/Stacks/Stacks_analyses_TRIMMED/Thesis_Incremental_runs//CRU_ONLY_TESTDIR_1/Final_Ustacks_outputs/ \n",
      "\n",
      "Parameter values: M =4 m =2\n",
      "\n",
      "BF04 ID = 2\n",
      "POLEN1 ID = 3\n",
      "PRO01 ID = 4\n",
      "#!/bin/bash\n",
      "\n",
      "mkdir /media/dan/34D5D1CE642D7E36/2013076_Hanfling_Bernd/Stacks/Stacks_analyses_TRIMMED/Thesis_Incremental_runs//CRU_ONLY_TESTDIR_2/Final_Ustacks_outputs/ \n",
      "ustacks -t fastq -M 4 -m 2 -p 8 -d -r -i 1 -f /media/dan/34D5D1CE642D7E36/2013076_Hanfling_Bernd/Stacks/Stacks_analyses_TRIMMED/Thesis_Incremental_runs//CRU_ONLY_TESTDIR_2/BF04_1.fil.fq_1 -o /media/dan/34D5D1CE642D7E36/2013076_Hanfling_Bernd/Stacks/Stacks_analyses_TRIMMED/Thesis_Incremental_runs//CRU_ONLY_TESTDIR_2/Final_Ustacks_outputs/ \n",
      "ustacks -t fastq -M 4 -m 2 -p 8 -d -r -i 2 -f /media/dan/34D5D1CE642D7E36/2013076_Hanfling_Bernd/Stacks/Stacks_analyses_TRIMMED/Thesis_Incremental_runs//CRU_ONLY_TESTDIR_2/POLEN1_RD-P1-170_1.fil.fq_1 -o /media/dan/34D5D1CE642D7E36/2013076_Hanfling_Bernd/Stacks/Stacks_analyses_TRIMMED/Thesis_Incremental_runs//CRU_ONLY_TESTDIR_2/Final_Ustacks_outputs/ \n",
      "ustacks -t fastq -M 4 -m 2 -p 8 -d -r -i 3 -f /media/dan/34D5D1CE642D7E36/2013076_Hanfling_Bernd/Stacks/Stacks_analyses_TRIMMED/Thesis_Incremental_runs//CRU_ONLY_TESTDIR_2/PRO01_1.fil.fq_1 -o /media/dan/34D5D1CE642D7E36/2013076_Hanfling_Bernd/Stacks/Stacks_analyses_TRIMMED/Thesis_Incremental_runs//CRU_ONLY_TESTDIR_2/Final_Ustacks_outputs/ \n",
      "\n",
      "Parameter values: M =4 m =2\n",
      "\n",
      "SK1 ID = 2\n",
      "TROM02 ID = 3\n",
      "V1 ID = 4\n",
      "#!/bin/bash\n",
      "\n",
      "mkdir /media/dan/34D5D1CE642D7E36/2013076_Hanfling_Bernd/Stacks/Stacks_analyses_TRIMMED/Thesis_Incremental_runs//CRU_ONLY_TESTDIR_3/Final_Ustacks_outputs/ \n",
      "ustacks -t fastq -M 4 -m 2 -p 8 -d -r -i 1 -f /media/dan/34D5D1CE642D7E36/2013076_Hanfling_Bernd/Stacks/Stacks_analyses_TRIMMED/Thesis_Incremental_runs//CRU_ONLY_TESTDIR_3/SK1_RD-P1-128_1.fil.fq_1 -o /media/dan/34D5D1CE642D7E36/2013076_Hanfling_Bernd/Stacks/Stacks_analyses_TRIMMED/Thesis_Incremental_runs//CRU_ONLY_TESTDIR_3/Final_Ustacks_outputs/ \n",
      "ustacks -t fastq -M 4 -m 2 -p 8 -d -r -i 2 -f /media/dan/34D5D1CE642D7E36/2013076_Hanfling_Bernd/Stacks/Stacks_analyses_TRIMMED/Thesis_Incremental_runs//CRU_ONLY_TESTDIR_3/TROM02_1.fil.fq_1 -o /media/dan/34D5D1CE642D7E36/2013076_Hanfling_Bernd/Stacks/Stacks_analyses_TRIMMED/Thesis_Incremental_runs//CRU_ONLY_TESTDIR_3/Final_Ustacks_outputs/ \n",
      "ustacks -t fastq -M 4 -m 2 -p 8 -d -r -i 3 -f /media/dan/34D5D1CE642D7E36/2013076_Hanfling_Bernd/Stacks/Stacks_analyses_TRIMMED/Thesis_Incremental_runs//CRU_ONLY_TESTDIR_3/V1_1.fil.fq_1 -o /media/dan/34D5D1CE642D7E36/2013076_Hanfling_Bernd/Stacks/Stacks_analyses_TRIMMED/Thesis_Incremental_runs//CRU_ONLY_TESTDIR_3/Final_Ustacks_outputs/ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "## batch final ustacks\n",
    "\n",
    "for root, dirs, files in os.walk(\"/media/dan/34D5D1CE642D7E36/2013076_Hanfling_Bernd/Stacks/Stacks_analyses_TRIMMED/Thesis_Incremental_runs/\"):\n",
    "    for dir in dirs:\n",
    "        if \"CRU_ONLY_TESTDIR\" in dir and \"reference\" not in root:\n",
    "            parent_dir = root+\"/\"+dir\n",
    "            Final_Ustacks_command(4, 2, str(parent_dir+\"/\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
