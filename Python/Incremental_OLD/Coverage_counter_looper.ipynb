{
 "metadata": {
  "name": "",
  "signature": "sha256:977a41af5b00b22ce93f1e159567081bbe7f8f9409b7a87d5ea59bf5f50b52ec"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Coverage Counter, to iterate over tsv files in subdirectories and produce histograms of coverage"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np ## Put the imports in here because, for some reason, have to import them each time a new kernel starts, or the plots are plotted over eachother\n",
      "import collections\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "import matplotlib.pylab as py\n",
      "import os\n",
      "import csv\n",
      "\n",
      "def coverage_counter(file_name):\n",
      "    csvcol3 = []\n",
      "    csvfile = open(file_name, 'rb')\n",
      "    csvread = csv.reader(csvfile, delimiter =\"\\t\") ## read csv in\n",
      "    \n",
      "    for line in csvread:\n",
      "        csvcol3.append(int(line[2])) ## add the 3 column of each line to a list\n",
      "    csvcol3 = [int(i) for i in csvcol3] ## convert this list of integers to strings\n",
      "    \n",
      "    coverage_count = collections.Counter()\n",
      "    for tagID in csvcol3:\n",
      "        coverage_count[tagID] += 1 ## count the number of times each tag ID occurs (i.e. the coverage)\n",
      "    \n",
      "    coverage_values = []\n",
      "    f = open(str(file_name[:-9]+\" Coverage data.txt\"), 'a') ## make a new txt file for coverage data\n",
      "    \n",
      "    for i,j in coverage_count.iteritems():\n",
      "        coverage_values.append(j) ## append the coverage to a list\n",
      "        f.write(str(j) + \"\\n\") ## write the coverage data to the txt file\n",
      "    \n",
      "    plt.hist(coverage_values, bins = max(coverage_values),range = [0, 100])\n",
      "    plt.hist(coverage_values, bins = max(coverage_values),range = [0, 100])\n",
      "    plt.title(file_name[2:8]+file_name[27:33])\n",
      "    plt.xlabel(\"Coverage\")\n",
      "    plt.ylabel(\"Frequency\")\n",
      "    plt.text(60, 1200, \"Mean tag coverage =\"+ str(np.round(np.mean(coverage_values),2)))\n",
      "    plt.savefig(file_name.rpartition('/')[0]+\"/Coverage.pdf\")\n",
      "    plt.close()\n",
      "    \n",
      "    f.close()\n",
      "    print coverage_values[:10]\n",
      "\n",
      "    ## look into the ggplot2 module for python to make a nicer looking graph\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Coverage_counter_looper(): Loops over the parent directory given with coverage counter \n",
      "- calculates the coverage per tag, for each sample and incrementation\n",
      "- makes a histogram per sample and increment and puts it in the respective folder\n",
      "- makes the coverage multiplot and puts it in the parent directory\n",
      "- prints the first 10 coverage values as a test that its working\n",
      "- prints the coverage data to a file for any further use\n",
      "- Then makes the change-in-av-coverage plot and puts in the parent dir.\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def coverage_counter_looper(directory): ## make sure this is the right parent directory - i.e. contains the sample name folder created by increMental\n",
      "    tsvs = []\n",
      "    subdirs = []\n",
      "    cov_files = []\n",
      "    \n",
      "    ## Make a list of the files, including their paths from the current directory\n",
      "    \n",
      "    for root, dirs, files in os.walk(str(directory)):\n",
      "        for fil in files:\n",
      "            if fil.endswith(\".tags.tsv\"):\n",
      "                tsvs.append(str(str(root)+'/'+str(fil)))\n",
      "                subdirs.append(str(str(root)+'/'+str(dirs)))\n",
      "                \n",
      "    \n",
      "    ## Execute coverage counter for all these files\n",
      "    \n",
      "    for tsv in tsvs:\n",
      "        coverage_counter(tsv)           \n",
      "    \n",
      "    ## make the multiplot\n",
      "    ## first get the coverage counter output files\n",
      "    \n",
      "    for root, dirs, files in os.walk(str(directory)):\n",
      "        for fil in files:\n",
      "            if fil.endswith(\"data.txt\") and 'catalog' not in fil:  ## have changed this so hopefully it doesn't pick up increMental_C outputs\n",
      "                cov_files.append(str(str(root)+'/'+str(fil)))\n",
      "    \n",
      "    plot_number = 1\n",
      "\n",
      "    fig = plt.figure()\n",
      "    plt.subplots_adjust(hspace = 0.8)\n",
      "\n",
      "    for cov_file in cov_files:    \n",
      "        data_file = open(cov_file, 'r')\n",
      "        data = [int(i) for i in data_file.readlines()]\n",
      "    \n",
      "        fig.add_subplot(np.round((len(cov_files)/3)+1),3,plot_number)\n",
      "        plt.hist(data, bins = 100,range = [0, 150])\n",
      "        plt.title(cov_file.split('/')[1].partition('_')[0]+\" \"+ cov_file.split('/')[3], fontsize = 5)\n",
      "        py.yticks(fontsize = 5)\n",
      "        py.xticks(fontsize = 5)\n",
      "        plt.xlabel(\"Coverage\", fontsize = 5)\n",
      "        plt.ylabel(\"Frequency\", fontsize = 5)\n",
      "        plt.text(60, 1200, \"Mean tag coverage =\"+ str(np.round(float(np.mean(data)),2)), fontsize = 5)\n",
      "    \n",
      "        plot_number += 1\n",
      "\n",
      "    plt.savefig('./coverage_multiplot.pdf')    \n",
      "    plt.close('all')\n",
      "    \n",
      "    \n",
      "    print('number of coverage plots = '+ str(plot_number -1))\n",
      "    \n",
      "    ### Make the change-in average coverage plot\n",
      "    \n",
      "    sample_coverage = []\n",
      "    sample_names = []\n",
      "    cov_data = []\n",
      "    cov_values = []\n",
      "\n",
      "    ## Define a cool little helper function for \"natural sorting\". (no idea how it works though!)\n",
      "\n",
      "    import re\n",
      "    def natural_key(string_): \n",
      "        return [int(s) if s.isdigit() else s for s in re.split(r'(\\d+)', string_)]\n",
      "\n",
      "    ## get file names and paths\n",
      "\n",
      "    for root, dirs, files in os.walk(str('./')):\n",
      "        for fil in files:\n",
      "            if fil.endswith(\"data.txt\"):\n",
      "                data_file = open(str(root+'/'+fil), 'r')\n",
      "                data = [int(i) for i in data_file.readlines()]\n",
      "                sample_coverage.append(fil.partition('_')[0] + \"__\" + root.split('/')[3]+\"\\t\"+ str(np.round(np.mean(data),2)))\n",
      "\n",
      "    ## make a list of uniq sample names\n",
      "\n",
      "    for i in sample_coverage:\n",
      "        sample_names.append(i.split('\\t')[0].partition('_')[0])\n",
      "    sample_names = set(sample_names)\n",
      "    print \"sample names =\" \n",
      "    print sample_names\n",
      "\n",
      "    ## Use this list to separate the data according to the sample it comes from\n",
      "    ## And then plot the graphs in one file and save in parent directory\n",
      "\n",
      "    fig = plt.figure() ## make fig\n",
      "    plt.subplots_adjust(hspace = 0.5) ## adjust subplots\n",
      "    plot_number =1\n",
      "    for name in sample_names: ## for each sample\n",
      "        for line in sample_coverage:\n",
      "            if name in line:\n",
      "                cov_data.append(line)\n",
      "        cov_data = sorted(cov_data, key = natural_key) ## sort \"naturally\"\n",
      "        for i in cov_data:\n",
      "            cov_values.append(float(i.split()[1]))\n",
      "        print name\n",
      "        print cov_values\n",
      "    \n",
      "    ## And now plot the graphs as subplots in a main fig. Put in parent dir.   \n",
      "    \n",
      "        fig.add_subplot(np.round((len(sample_names)/2)+1),2,plot_number)\n",
      "        plt.scatter(range(0,16,2),cov_values) ## Manually input range from IncreMental here!\n",
      "        plt.plot(range(0,16,2),cov_values)\n",
      "        plt.title(name+\" coverage per tag with incrementation\", fontsize = 10)\n",
      "        plt.xlabel(\"Ustacks Parameter Value\", fontsize = 10)\n",
      "        plt.ylabel(\"Coverage per tag\", fontsize = 10)\n",
      "        plt.xticks(fontsize = 7)\n",
      "        plt.yticks(fontsize = 7)\n",
      "    \n",
      "        cov_data = []\n",
      "        cov_values = []\n",
      "        plot_number+=1\n",
      "    plt.savefig(\"mean_coverage_multiplot.pdf\")\n",
      "    plt.close('all')    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Note the font and line width sizes on the histograms are a bit messy, if I am trying to make this more polished I can make the relative to the number of plots quite easily."
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "coverage_counter_looper('./')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[10, 8, 23, 15, 16, 8, 17, 14, 15, 10]\n",
        "[346, 266, 71, 986, 1238, 71, 137, 1751, 341, 214]"
       ]
      }
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## A good way to split path names for use in file saving - much more robust to different sample name lengths etc."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "path = './CAKE10_RD-P1-178_1/M_tests/M_0/CAKE10_RD-P1-178_1.tags.tsv'\n",
      "\n",
      "print(path.split('/')) ## gives a list of the delimited sections of the string\n",
      "\n",
      "print(path.partition('/'))## gives a list of everything BEFORE the FIRST occurance of the delimiter, the delimiter and everything left\n",
      "\n",
      "print(path.rpartition('/')[0]) ## gives a string of everything BEFORE the LAST occurance of delimiter - very good for file paths\n",
      "\n",
      "print(path.split('/')[1].partition('_')[0]+ \" \" + path.split('/')[3]) ## combined here"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['.', 'CAKE10_RD-P1-178_1', 'M_tests', 'M_0', 'CAKE10_RD-P1-178_1.tags.tsv']\n",
        "('.', '/', 'CAKE10_RD-P1-178_1/M_tests/M_0/CAKE10_RD-P1-178_1.tags.tsv')\n",
        "./CAKE10_RD-P1-178_1/M_tests/M_0\n",
        "CAKE10 M_0\n"
       ]
      }
     ],
     "prompt_number": 74
    }
   ],
   "metadata": {}
  }
 ]
}